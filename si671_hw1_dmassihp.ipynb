{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'trainML.csv' does not exist: b'trainML.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-139a7e0f760f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainML.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testML.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainRec.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'trainML.csv' does not exist: b'trainML.csv'"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "df1 = pd.read_csv('trainML.csv')\n",
    "df2 = pd.read_csv('testML.csv')\n",
    "df3 = pd.read_csv('trainRec.csv')\n",
    "df4 = pd.read_csv('testRec.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender        0\n",
       "match         0\n",
       "samerace      0\n",
       "age_o        67\n",
       "race_o       58\n",
       "pf_o_att     58\n",
       "pf_o_sin     58\n",
       "pf_o_int     58\n",
       "pf_o_fun     67\n",
       "pf_o_amb     76\n",
       "pf_o_sha     76\n",
       "attr_o       97\n",
       "sinc_o      138\n",
       "intel_o     142\n",
       "fun_o       161\n",
       "met_o       168\n",
       "age          67\n",
       "field        58\n",
       "race         58\n",
       "imprace      58\n",
       "imprelig     58\n",
       "from         58\n",
       "goal         58\n",
       "date         58\n",
       "go_out       58\n",
       "career       68\n",
       "career_c     68\n",
       "sports       58\n",
       "tvsports     58\n",
       "exercise     58\n",
       "           ... \n",
       "museums      58\n",
       "art          58\n",
       "hiking       58\n",
       "gaming       58\n",
       "clubbing     58\n",
       "reading      58\n",
       "tv           58\n",
       "theater      58\n",
       "movies       58\n",
       "concerts     58\n",
       "music        58\n",
       "shopping     58\n",
       "yoga         58\n",
       "attr1_1      58\n",
       "sinc1_1      58\n",
       "intel1_1     58\n",
       "fun1_1       67\n",
       "amb1_1       76\n",
       "attr3_1      58\n",
       "sinc3_1      58\n",
       "fun3_1       58\n",
       "intel3_1     58\n",
       "attr         97\n",
       "sinc        138\n",
       "intel       142\n",
       "fun         161\n",
       "met         168\n",
       "iid           0\n",
       "pid           0\n",
       "shar1_1      76\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discover the NAN/missing values in the dataframe\n",
    "df1.isnull().sum()\n",
    "\n",
    "# There are quite a few variables with around 150 missing variables, and considering\n",
    "#  the size of our dataset, this corresponds to around 150/3808 or about 3.9% missing \n",
    "#  rows for these columns.  This relatively low percentage does not seem too concerning \n",
    "#  and did not lead me to remove any variables from the list of potential predictors\n",
    "#  solely on the basis of having too many NAN entries.\n",
    "\n",
    "# Note that since there are no NAN values for out target variable match, we \n",
    "#  do not need to remove any rows with regards to the match variable.  However,\n",
    "#  I decided to remove all rows where any variable contains an NA value, shown \n",
    "#  several cells below when I did all the main modifications to my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "2\n",
      "match\n",
      "2\n",
      "samerace\n",
      "2\n",
      "age_o\n",
      "22\n",
      "race_o\n",
      "6\n",
      "pf_o_att\n",
      "32\n",
      "pf_o_sin\n",
      "31\n",
      "pf_o_int\n",
      "25\n",
      "pf_o_fun\n",
      "25\n",
      "pf_o_amb\n",
      "27\n",
      "pf_o_sha\n",
      "27\n",
      "attr_o\n",
      "17\n",
      "sinc_o\n",
      "14\n",
      "intel_o\n",
      "17\n",
      "fun_o\n",
      "17\n",
      "met_o\n",
      "5\n",
      "age\n",
      "22\n",
      "field\n",
      "153\n",
      "race\n",
      "6\n",
      "imprace\n",
      "11\n",
      "imprelig\n",
      "11\n",
      "from\n",
      "155\n",
      "goal\n",
      "7\n",
      "date\n",
      "8\n",
      "go_out\n",
      "8\n",
      "career\n",
      "202\n",
      "career_c\n",
      "16\n",
      "sports\n",
      "11\n",
      "tvsports\n",
      "11\n",
      "exercise\n",
      "11\n",
      "dining\n",
      "10\n",
      "museums\n",
      "10\n",
      "art\n",
      "11\n",
      "hiking\n",
      "11\n",
      "gaming\n",
      "12\n",
      "clubbing\n",
      "11\n",
      "reading\n",
      "11\n",
      "tv\n",
      "11\n",
      "theater\n",
      "11\n",
      "movies\n",
      "10\n",
      "concerts\n",
      "11\n",
      "music\n",
      "10\n",
      "shopping\n",
      "11\n",
      "yoga\n",
      "11\n",
      "attr1_1\n",
      "32\n",
      "sinc1_1\n",
      "31\n",
      "intel1_1\n",
      "25\n",
      "fun1_1\n",
      "25\n",
      "amb1_1\n",
      "27\n",
      "attr3_1\n",
      "10\n",
      "sinc3_1\n",
      "10\n",
      "fun3_1\n",
      "10\n",
      "intel3_1\n",
      "7\n",
      "attr\n",
      "17\n",
      "sinc\n",
      "14\n",
      "intel\n",
      "17\n",
      "fun\n",
      "17\n",
      "met\n",
      "6\n",
      "iid\n",
      "257\n",
      "pid\n",
      "257\n",
      "shar1_1\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# Now lets check the number of unique values for each of the variables to \n",
    "#  determine if there are any variables for which all the rows have the same\n",
    "#  value.  This will help us when we are deciding which variables to include\n",
    "#  in our models because we can remove any such variables from our dataset.\n",
    "for col in df1:\n",
    "    print (col),\n",
    "    print(len((df1[col].unique())))\n",
    "    \n",
    "# We can see that there are no variables that have only one value for all the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "[0 1]\n",
      "match\n",
      "[0 1]\n",
      "samerace\n",
      "[0 1]\n",
      "age_o\n",
      "[29. 22. 27. 28. 26. 21. 25. 24. 23. nan 39. 30. 32. 34. 35. 18. 20. 19.\n",
      " 33. 36. 31. 55.]\n",
      "race_o\n",
      "[ 3.  6.  1.  2. nan  4.]\n",
      "pf_o_att\n",
      "[20.   21.   50.   25.   60.   30.   17.   10.     nan  5.   15.   18.\n",
      " 40.   19.   14.   80.   35.   24.   27.   23.    0.   16.67 22.    7.\n",
      " 16.    6.67  2.   20.51 31.58 75.   12.    9.  ]\n",
      "pf_o_sin\n",
      "[25.   15.   17.   10.   20.    0.   18.     nan  7.   30.    8.    5.\n",
      " 24.   32.   21.    3.   40.   16.   16.67 14.   35.   19.   13.   19.05\n",
      " 47.   60.   12.   22.   14.53 10.53 26.  ]\n",
      "pf_o_int\n",
      "[15.   20.   22.   30.    0.   19.   18.     nan 25.   45.   17.   10.\n",
      " 35.   21.   50.    5.   28.   16.67 40.   42.86 16.   24.79 15.79 27.\n",
      " 23.  ]\n",
      "pf_o_fun\n",
      "[15.   20.   10.   30.     nan 25.   17.   19.   22.   23.   12.    5.\n",
      " 18.   24.   35.   14.   16.67  9.52  8.   16.   17.09 21.05 27.   50.\n",
      "  0.  ]\n",
      "pf_o_amb\n",
      "[53.    5.    8.    0.   15.   10.   17.     nan 13.    6.   20.   11.\n",
      "  2.   18.   12.    4.    7.   25.   16.67 14.   14.29 16.    3.    5.98\n",
      " 10.53 30.    9.  ]\n",
      "pf_o_sha\n",
      "[20.   10.   13.    0.   15.     nan 14.   22.    5.    8.   30.   25.\n",
      " 18.    6.    2.   16.67 12.    7.62 16.   11.    1.   17.09 10.53  9.\n",
      "  7.   17.   19.  ]\n",
      "attr_o\n",
      "[ 7.   8.   6.   9.   4.   5.   nan  3.   0.   2.  10.   1.   6.5  7.5\n",
      "  8.5  9.5  9.9]\n",
      "sinc_o\n",
      "[ 6.   8.   4.   5.   7.  10.   9.   nan  1.   2.   3.   8.5  0.   7.5]\n",
      "intel_o\n",
      "[ 6.   7.   5.   8.   nan  4.   9.  10.   2.   0.   3.   6.5  8.5  1.\n",
      "  7.5  9.5  5.5]\n",
      "fun_o\n",
      "[ 7.   6.  10.   5.   8.   nan  2.   4.   3.   9.   1.   0.   5.5  6.5\n",
      "  9.5  7.5  8.5]\n",
      "met_o\n",
      "[ 2. nan  1.  3.  5.]\n",
      "age\n",
      "[23. 22. nan 29. 28. 26. 24. 27. 21. 25. 34. 35. 32. 30. 39. 20. 19. 18.\n",
      " 33. 36. 31. 55.]\n",
      "field\n",
      "['social work' 'Social Work' nan 'psychology' 'German Literature' 'law'\n",
      " 'Law' 'Business & International Affairs' 'MFA Creative Writing' 'MBA'\n",
      " 'Engineering' 'Electrical Engineering' 'Classics'\n",
      " 'Operations Research (SEAS)' 'chemistry' 'Journalism'\n",
      " 'Elementary/Childhood Education (MA)' 'Economics' 'microbiology'\n",
      " 'Masters of Social Work' 'Communications' 'Marketing' 'Chemistry'\n",
      " 'International Educational Development' 'Education Administration'\n",
      " 'Business (MBA)' 'Business' 'Computer Science'\n",
      " 'Climate-Earth and Environ. Science' 'financial math' 'Business- MBA'\n",
      " 'Religion' 'Film' 'Sociology' 'Economics, English' 'political science'\n",
      " 'Economics, Sociology' 'Polish' 'English' 'psychology and english'\n",
      " 'Biomedical Engineering' 'Economics and Political Science'\n",
      " 'Art History/medicine' 'philosophy' 'Mechanical Engineering'\n",
      " 'Political Science' 'sociology' 'Philosophy and Physics' 'nutrition'\n",
      " 'Medicine' 'Art Education' 'MA Science Education' 'Genetics' 'biology'\n",
      " 'Psychology' 'Law and English Literature (J.D./Ph.D.)' 'french'\n",
      " 'Nutritiron' 'GS Postbacc PreMed' 'Art History' 'Biology'\n",
      " 'Operations Research' 'Molecular Biology' 'Genetics & Development'\n",
      " 'medical informatics' 'Electrical Engg.' 'Business School' 'engineering'\n",
      " 'Mathematics' 'International Politics'\n",
      " 'MBA / Master of International Affairs (SIPA)' 'genetics'\n",
      " 'medicine and biochemistry' 'International Affairs'\n",
      " 'Social Studies Education' 'MA Teaching Social Studies'\n",
      " 'Education Policy' 'Education- Literacy Specialist'\n",
      " 'Anthropology/Education' 'bilingual education' 'speech pathology'\n",
      " 'Education' 'Speech Pathology' 'math education' 'TESOL'\n",
      " 'Elementary Education' 'Cognitive Studies in Education' 'education'\n",
      " 'Finance/Economics' 'Museum Anthropology' 'Environmental Engineering'\n",
      " 'Business Administration' 'Curriculum and Teaching/Giftedness' 'History'\n",
      " 'Anthropology' 'Instructional Tech & Media' 'School Psychology'\n",
      " 'Instructional Media and Technology' 'SIPA / MIA' 'English Education'\n",
      " 'art education' 'MA in Quantitative Methods' 'Early Childhood Education'\n",
      " 'anthropology' 'Architecture' 'Urban Planning'\n",
      " 'Ed.D. in higher education policy at TC' 'Epidemiology'\n",
      " 'International Security Policy - SIPA' 'Nutrition' 'EDUCATION'\n",
      " 'Organizational Psychology' 'Applied Physiology & Nutrition'\n",
      " 'music education' 'Music Education' 'Clinical Psychology'\n",
      " 'Counseling Psychology' 'Communications in Education'\n",
      " 'Intellectual Property Law' 'MBA Finance' 'Intrernational Affairs'\n",
      " 'BUSINESS CONSULTING' 'business' 'business school' 'MFA  Poetry'\n",
      " 'SOA -- writing' 'Finance' 'biomedical informatics' 'physics'\n",
      " 'art history' 'working' 'Consulting' 'Human Rights: Middle East'\n",
      " 'Human Rights' 'medicine' 'Biotechnology' 'biotechnology'\n",
      " 'SIPA-International Affairs' 'International affairs'\n",
      " 'teaching of English' 'GSAS' 'African-American Studies/History'\n",
      " 'Neurosciences/Stem cells' 'film' 'Public Administration' 'journalism'\n",
      " 'Theater' 'Biology PhD' 'biochemistry/genetics' 'epidemiology' 'Stats'\n",
      " 'Statistics' 'math of finance']\n",
      "race\n",
      "[ 2. nan  6.  3.  4.  1.]\n",
      "imprace\n",
      "[10. nan  3.  1.  6.  2.  5.  8.  7.  4.  9.]\n",
      "imprelig\n",
      "[ 9. 10. nan  5.  1.  3.  2.  7.  4.  8.  6.]\n",
      "from\n",
      "['Florida' 'New Jersey' nan 'Tuscaloosa, Alabama' 'Albuquerque, NM'\n",
      " 'Palo Alto, California' 'New York' 'Boston, MA' 'Mexico' 'Torrance, CA'\n",
      " 'St. Louis, MO' 'London, UK' 'Minnesota' 'Chicago' 'Spain' 'Philadelphia'\n",
      " 'Ohio' 'India/Venezuela' 'China' 'Texas' 'Washington State' 'Panama'\n",
      " 'spain' 'Arizona' 'Minneapolis, MN' 'NJ' 'NY' 'Israel' 'P. R. China'\n",
      " 'California' 'San Francisco' 'England' 'Bangladesh' 'Long Island'\n",
      " 'Argentina' 'Brooklyn, NY' 'Cincinnati, Ohio' 'India' 'Canada' 'Colorado'\n",
      " 'Ann Arbor, MI' 'Hong Kong' 'Ann Arbor' 'Philippines'\n",
      " 'Milwaukee, Wisconsin' 'brooklyn ny' 'France' 'Long Island, NY'\n",
      " 'Puerto Rico' 'Memphis, TN' 'Louisiana' 'Maryland' 'Staten Island'\n",
      " 'New York, NY' 'Massachusetts' 'Connecticut' 'India, Holland' 'Japan'\n",
      " 'Boulder, Colorado' 'Northern Virginia' 'I am from NYC' 'Seattle'\n",
      " 'Malaysia, then Massachusetts' 'Katonah, NY (more recently, Boston)'\n",
      " 'Warsaw, Poland' 'Washington, D.C.' 'new york city' 'Taiwan' 'Toronto'\n",
      " 'czech republic' 'Siberia' 'New Hope, PA' 'boston, ma'\n",
      " 'Las Vegas, Nevada' 'Budapest' 'Russia' 'UNCC' 'Boston' 'Iceland'\n",
      " 'International Student' 'Nepal' 'Washington, DC' 'New York City'\n",
      " 'Northern New Jersey' 'Buffalo, NY' 'NYC-6 yrs. Grew up in Nebraska'\n",
      " 'philippines' 'Virginia' 'Cambridge, Massachusetts' 'NYC'\n",
      " 'New Delhi, India' 'way too little space here. world citizen.' 'Italy'\n",
      " 'Ottawa, Canada' 'Pennsylvania' 'France  / New York' 'Tokyo and Texas'\n",
      " 'Erie, PA' 'Westchester, new York' 'USA/American' 'Great Neck, NY'\n",
      " 'California (West Coast)' 'japan' 'Portland, OR'\n",
      " 'New York/South Korea/Japan' 'Michigan' 'Miami' 'Dallas, Texas'\n",
      " 'Bombay, India' 'Palo Alto, CA' 'New Mexico' 'Brooklyn'\n",
      " 'WASHINGTON, D.C.' 'CALIFORNIA' 'Manhattan' 'atlanta, ga'\n",
      " 'California and New York' 'Bronx Science' 'nashville, TN' 'Australia'\n",
      " 'Toronto, Canada' 'UK/Turkey' 'Midwest USA' 'Costa Rica' 'SOUTH KOREA'\n",
      " 'Yugoslavia' 'los angeles' 'new york' 'Wisconsin'\n",
      " 'Santa Barbara, California' 'india' 'Cambridge, MA' 'Singapore'\n",
      " 'Texas/London' 'CT, FL, TN' 'Detroit suburbs' 'Tokyo, Japan'\n",
      " 'south carolina' 'California, New Jersey' 'Belgium' 'alabama'\n",
      " 'Washington DC' 'colorado' 'Westchester County, N.Y.' 'Romania'\n",
      " 'Los Angeles' 'South Orange, New Jersey' 'Colombia, South America'\n",
      " 'Greece' 'Indiana' 'Boston, Ma' 'Baltimore' 'Kansas City, Missouri'\n",
      " 'Upstate New York' 'Manila, Philippines']\n",
      "goal\n",
      "[ 1.  3. nan  4.  2.  6.  5.]\n",
      "date\n",
      "[ 3.  5. nan  6.  7.  4.  2.  1.]\n",
      "go_out\n",
      "[ 1.  2. nan  5.  3.  4.  7.  6.]\n",
      "career\n",
      "['social worker' 'Social Worker' nan 'comedienne' 'Academic' 'attorney'\n",
      " 'Undecided' 'Social Worker.... Clinician' 'Private Equity Investing'\n",
      " 'Lawyer or professional surfer' 'novelist' 'banker' 'Investment Banking'\n",
      " 'Pro Beach Volleyball' 'Engineer or iBanker or consultant' 'Trading'\n",
      " 'Ph.D. Electrical Engineering' 'teacher' 'Counseling Adolescents'\n",
      " 'Operations Research' 'industrial scientist' 'Journalism'\n",
      " 'teaching and then...' 'Economic research' 'pharmaceuticals'\n",
      " 'Social Services/ Policy' 'Professor of Media Studies'\n",
      " 'Clinical Social Worker' \"I don't know\" 'Lawyer'\n",
      " 'Microfinancing Program Manager' 'Education Administration' 'Marketing'\n",
      " 'Business - Investment Management' 'Academic or Research staff'\n",
      " 'Professor' 'University Professor' 'Finance' 'Research Scientist'\n",
      " 'business' 'research in industry or academia' 'Law' 'Teacher/Professor'\n",
      " 'Engineering' 'film' 'Writer' 'consulting' 'Social work'\n",
      " 'What a question!' 'psychologist' 'if only i knew'\n",
      " 'Marketing, Advertising' 'lawyer/gov.position'\n",
      " 'no idea, maybe a professor' 'Cardiologist' 'Law or finance' 'Pediatrics'\n",
      " 'medicine' 'Porn Star' 'Mechanical Engineering' 'entrepeneur'\n",
      " \"don't know\" 'Not Sure' 'researcher/academia' 'academia'\n",
      " 'nutrition and dental' 'Physician' 'Art educator and Artist' 'Teacher'\n",
      " 'Scientist' 'Scientist/educator'\n",
      " 'scientific research for now but who knows' 'Who knows'\n",
      " 'College Professor' 'Professor or Lawyer' 'undecided' 'dietician'\n",
      " 'Medicine' 'professor' 'Researcher' 'Social Work'\n",
      " 'research position in pharmaceutical industry' 'Academia'\n",
      " 'research/academia' 'research' 'enterpreneur' 'Industry CTO/CEO'\n",
      " 'Film/Television' 'finance or engineering' 'Writing'\n",
      " 'Venture Capital/Consulting/Government' 'doctor and entrepreneur'\n",
      " \"Int'l Business\" 'Pharmaceuticals/Consulting'\n",
      " 'Secondary Education Teacher' 'High School Social Studies Teacher'\n",
      " 'Education Policy Analyst'\n",
      " 'Literacy Organization head/ Director of Development for non-profit'\n",
      " 'English Teacher' 'Program development / policy work'\n",
      " 'professor of education' 'speech pathologist' 'Educator'\n",
      " 'Speech Pathologist' 'teaching/education' 'professor in college'\n",
      " 'Academia; Research; Teaching' 'curriculum developer' '?' 'Entrepreneur'\n",
      " 'Museum Work (Curation?)' 'Music Industry' 'academic or consulting'\n",
      " 'Academia or UN' 'Investment banking' 'International Development banker'\n",
      " 'Corporate Finance, Asset Management/ Hedge Funds' 'I am a teacher.'\n",
      " 'Professor or journalist' 'to get Ph.D and be a professor' 'Education'\n",
      " 'school psychologist' 'School Psychologist' 'Consulting'\n",
      " 'not sure yet :)' 'Early Childhood Ed. - College/univ. faculity'\n",
      " 'medical examiner or researcher' 'Healthcare' 'Architecture and design'\n",
      " 'Civil Engineer' 'Real Estate Consulting' 'University President'\n",
      " 'Epidemiologist' 'Security Policy - Homeland Defense' 'Nutritionist'\n",
      " 'GOVERNOR' 'EDUCATION ADMINISTRATION'\n",
      " 'Director of Training and Development' 'Private practice Dietician'\n",
      " 'music educator, performer' 'Artist' 'Clinical Psychology'\n",
      " 'Clinical Psychologist' 'Psychologist' 'education'\n",
      " 'Marketing or Strategy and Business Development'\n",
      " 'reorganizing society. no, I am not being flip.'\n",
      " 'Intellectual Property Attorney' 'investment banking' 'Make money'\n",
      " 'Art Management' 'Political Development in Africa' 'Journalist'\n",
      " 'clinical psychologist, researcher, professor' 'Intl Development'\n",
      " 'Business Consulting' 'CONSULTING' 'Private Equity' 'still wondering'\n",
      " 'investment management' 'Finance Related' 'Research'\n",
      " 'Health care finance' 'writer' 'Entrepreneurship'\n",
      " 'Fixed Income Sales & Trading' 'physician, informaticist'\n",
      " 'Professor, or Engineer' 'Not sure yet' 'Management Consulting'\n",
      " 'playing music' 'unknown' 'Consulting, later Arts or Non-Profit'\n",
      " 'Professor; Human Rights Director' 'Work at the UN' 'physician'\n",
      " 'Urban Planner' 'Clinic Trial' 'scientist' 'International Development'\n",
      " 'Engineer' 'Finance/Economics' 'Banking' 'Planning' 'English teacher'\n",
      " 'professional career' 'writer/teacher' 'Medical Sciences' 'Professor...?'\n",
      " 'Business' 'writer/producer' 'Investment Banker' 'acadeic' 'politics'\n",
      " 'film and radio' 'Film' 'researcher' 'biology industry' 'epidemiologist'\n",
      " 'consultant' 'Writer/Editor' 'unsure']\n",
      "career_c\n",
      "[ 9. nan  6.  2.  1. 10.  3.  7. 14.  5. 11.  4. 12. 17. 13. 15.]\n",
      "sports\n",
      "[ 2.  4. nan  3.  1.  8.  5.  7.  9. 10.  6.]\n",
      "tvsports\n",
      "[ 1.  4. nan  5.  3.  8.  2.  9.  7. 10.  6.]\n",
      "exercise\n",
      "[10.  5. nan  9.  7.  8.  3.  6.  2.  4.  1.]\n",
      "dining\n",
      "[10.  9. nan  8.  6.  7.  5.  4.  3.  2.]\n",
      "museums\n",
      "[ 5.  9. nan 10.  6.  8.  4.  3.  7.  2.]\n",
      "art\n",
      "[ 5.  9. nan 10.  6.  8.  3.  2.  4.  7.  1.]\n",
      "hiking\n",
      "[ 2.  9. nan  3.  5.  7.  8.  4.  1.  6. 10.]\n",
      "gaming\n",
      "[ 1. nan  7.  5.  8.  6.  4.  3.  2.  9. 14.  0.]\n",
      "clubbing\n",
      "[ 7.  5. nan  2.  3.  9.  4.  6.  8.  1. 10.]\n",
      "reading\n",
      "[ 6.  9. nan  5. 10.  7.  8.  4.  2.  1.  3.]\n",
      "tv\n",
      "[ 8.  9. nan  2.  6.  3.  1.  7.  5.  4. 10.]\n",
      "theater\n",
      "[ 8.  9. nan 10.  2.  4.  3.  5.  7.  6.  1.]\n",
      "movies\n",
      "[ 7.  9. nan 10.  8.  6.  5.  2.  3.  4.]\n",
      "concerts\n",
      "[ 6.  9. nan  8.  7.  4.  5. 10.  3.  2.  1.]\n",
      "music\n",
      "[ 9. nan 10.  5.  8.  6.  7.  4.  2.  1.]\n",
      "shopping\n",
      "[10.  9. nan  5.  8.  6.  4.  2.  7.  3.  1.]\n",
      "yoga\n",
      "[ 4.  9. nan  5.  7.  2.  6.  1. 10.  3.  8.]\n",
      "attr1_1\n",
      "[17.   10.     nan  5.   15.   30.   20.   21.   50.   25.   60.   14.\n",
      " 18.   40.   19.   35.   80.    0.   16.67 22.    7.   16.   24.   27.\n",
      " 23.    6.67  2.   12.    9.   20.51 31.58 75.  ]\n",
      "sinc1_1\n",
      "[18.   20.     nan 15.   10.   25.   17.    0.   32.   30.   21.    3.\n",
      "  7.    8.    5.   24.   40.   16.67 14.   35.   16.   47.   19.   13.\n",
      " 19.05 60.   12.   22.   14.53 10.53 26.  ]\n",
      "intel1_1\n",
      "[18.   20.     nan 25.   45.   17.   15.   22.   30.    0.   19.   50.\n",
      " 10.   35.   21.    5.   16.67 40.   28.   16.   42.86 27.   23.   24.79\n",
      " 15.79]\n",
      "fun1_1\n",
      "[15.   20.     nan 25.   10.   17.   30.   12.    5.   18.   24.   19.\n",
      " 22.   23.   35.   16.67 14.   16.    9.52  8.   17.09 21.05 27.   50.\n",
      "  0.  ]\n",
      "amb1_1\n",
      "[17.   15.     nan 10.    0.   53.    5.    8.   20.   11.    2.   18.\n",
      " 13.    6.   12.   25.   16.67 14.    4.    7.   16.    3.   14.29 30.\n",
      "  5.98 10.53  9.  ]\n",
      "attr3_1\n",
      "[10.  6. nan  7.  9.  8.  5.  3.  4.  2.]\n",
      "sinc3_1\n",
      "[10. nan  9.  8.  7.  6.  5.  4.  3.  2.]\n",
      "fun3_1\n",
      "[ 9. 10. nan  7.  6.  5.  8.  3.  4.  2.]\n",
      "intel3_1\n",
      "[ 8.  9. nan 10.  7.  5.  6.]\n",
      "attr\n",
      "[ 2.   3.   5.   4.   8.   7.   9.  10.   6.   nan  0.   1.   6.5  7.5\n",
      "  9.5  8.5  9.9]\n",
      "sinc\n",
      "[ 6.   9.   7.  10.   8.   5.   nan  4.   2.   1.   3.   0.   8.5  7.5]\n",
      "intel\n",
      "[ 2.   9.   5.   8.   7.  10.   nan  6.   0.   3.   4.   6.5  8.5  1.\n",
      "  7.5  9.5  5.5]\n",
      "fun\n",
      "[ 3.   7.   5.   9.   6.   8.   2.  10.   4.   nan  0.   1.   5.5  6.5\n",
      "  9.5  7.5  8.5]\n",
      "met\n",
      "[ 2. nan  3.  1.  5.  0.]\n",
      "iid\n",
      "[355 538 489 386 427  80 162 401 525   2 150 214 515 528 291 522 271 359\n",
      "  75 175 239 111 433 394  59 391 360  47 457 211 379 460 147  60  25 543\n",
      " 370 133 526 105  78 169 238 475 278   9   4 364 462 429 307 135 220  72\n",
      "  38  63 503 531 450 329 397 400 420 548 107 264 547 529 287 479 335 293\n",
      " 257 527 130 337  79  34 236 519 374 352  74  52 253 456 280  31  56 331\n",
      "  26 507 230  87 321 285 501  57 417 402 260 134 361 412 458 346 375  39\n",
      " 309 350 103  48 452 447 143 413  49 461 284 300 443 304 495 334 393   6\n",
      " 476 338  14 126 268 165 127 288 275 546 436 358 163 550 343 242 530 444\n",
      " 283 141 409 251  88 332 282 316 535 390 326 259 255 416 108 340 363 116\n",
      " 170 299 172 273  32 109 207 114 488 226  23 440 298 115 167  81 468 136\n",
      " 502 122 129 289 215 509 498 294 132 500  84 483  99 466 474 533 512 208\n",
      "  93 277 250 328 219 490 190 392 451  51 102 354  71 290 348 183  29 286\n",
      " 469  40 434 494 405 160 148 349 104 523 121 485 198 202  82 482 187   1\n",
      "  77 478 181 465 228 292 518 505 222 312 139 487  28 318  12 414 435 497\n",
      " 319 520 540 174 445]\n",
      "pid\n",
      "[150 214 515 528 291 522 271 359  75 175 355 538 489 386 427  80 162 401\n",
      " 525   2 526 105  78 169 238 475 278   9   4 364 462 429 307 135 220  72\n",
      "  38  63 239 111 433 394  59 391 360  47 457 211 379 460 147  60  25 543\n",
      " 370 133 264 547 529 287 479 335 293 257 527 130 503 531 450 329 397 400\n",
      " 420 548 107 501  57 417 402 260 134 361 412 458 346 375  39 309 350 103\n",
      "  48 452 447 143 413  49 337  79  34 236 519 374 352  74  52 253 456 280\n",
      "  31  56 331  26 507 230  87 321 285 165 127 288 275 546 436 358 163 550\n",
      " 343 242 530 444 283 461 284 300 443 304 495 334 393   6 476 338  14 126\n",
      " 268 259 255 416 108 340 363 116 170 299 141 409 251  88 332 282 316 535\n",
      " 390 326 215 509 498 294 132 500  84 483  99 466 474 533 512 208  93 277\n",
      " 250 328 172 273  32 109 207 114 488 226  23 440 298 115 167  81 468 136\n",
      " 502 122 129 289 102 354  71 290 348 183 219 490 190 392 451  51 202  82\n",
      " 482 187   1  77 478 181 465 228 292 518 505 222 312  29 286 469  40 434\n",
      " 494 405 160 148 349 104 523 121 485 198 435 497 319 520 540 174 445 139\n",
      " 487  28 318  12 414]\n",
      "shar1_1\n",
      "[ 15.      nan  20.    10.   -28.    12.     0.     5.    18.     6.\n",
      "  14.    22.     8.    30.    25.     2.    16.65  13.    11.     7.61\n",
      "  16.     1.    17.1   10.52   9.    17.     7.    19.  ]\n"
     ]
    }
   ],
   "source": [
    "# Let's also check the unique values themselves.\n",
    "for col in df1:\n",
    "    print (col),\n",
    "    print ((df1[col].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'match', 'samerace', 'age_o', 'race_o', 'pf_o_att',\n",
       "       'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o',\n",
       "       'sinc_o', 'intel_o', 'fun_o', 'met_o', 'age', 'field', 'race',\n",
       "       'imprace', 'imprelig', 'from', 'goal', 'date', 'go_out', 'career',\n",
       "       'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums',\n",
       "       'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',\n",
       "       'movies', 'concerts', 'music', 'shopping', 'yoga', 'attr1_1', 'sinc1_1',\n",
       "       'intel1_1', 'fun1_1', 'amb1_1', 'attr3_1', 'sinc3_1', 'fun3_1',\n",
       "       'intel3_1', 'attr', 'sinc', 'intel', 'fun', 'met', 'iid', 'pid',\n",
       "       'shar1_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3808, 61)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the number of columns/rows\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3808 entries, 0 to 3807\n",
      "Data columns (total 61 columns):\n",
      "gender      3808 non-null int64\n",
      "match       3808 non-null int64\n",
      "samerace    3808 non-null int64\n",
      "age_o       3741 non-null float64\n",
      "race_o      3750 non-null float64\n",
      "pf_o_att    3750 non-null float64\n",
      "pf_o_sin    3750 non-null float64\n",
      "pf_o_int    3750 non-null float64\n",
      "pf_o_fun    3741 non-null float64\n",
      "pf_o_amb    3732 non-null float64\n",
      "pf_o_sha    3732 non-null float64\n",
      "attr_o      3711 non-null float64\n",
      "sinc_o      3670 non-null float64\n",
      "intel_o     3666 non-null float64\n",
      "fun_o       3647 non-null float64\n",
      "met_o       3640 non-null float64\n",
      "age         3741 non-null float64\n",
      "field       3750 non-null object\n",
      "race        3750 non-null float64\n",
      "imprace     3750 non-null float64\n",
      "imprelig    3750 non-null float64\n",
      "from        3750 non-null object\n",
      "goal        3750 non-null float64\n",
      "date        3750 non-null float64\n",
      "go_out      3750 non-null float64\n",
      "career      3740 non-null object\n",
      "career_c    3740 non-null float64\n",
      "sports      3750 non-null float64\n",
      "tvsports    3750 non-null float64\n",
      "exercise    3750 non-null float64\n",
      "dining      3750 non-null float64\n",
      "museums     3750 non-null float64\n",
      "art         3750 non-null float64\n",
      "hiking      3750 non-null float64\n",
      "gaming      3750 non-null float64\n",
      "clubbing    3750 non-null float64\n",
      "reading     3750 non-null float64\n",
      "tv          3750 non-null float64\n",
      "theater     3750 non-null float64\n",
      "movies      3750 non-null float64\n",
      "concerts    3750 non-null float64\n",
      "music       3750 non-null float64\n",
      "shopping    3750 non-null float64\n",
      "yoga        3750 non-null float64\n",
      "attr1_1     3750 non-null float64\n",
      "sinc1_1     3750 non-null float64\n",
      "intel1_1    3750 non-null float64\n",
      "fun1_1      3741 non-null float64\n",
      "amb1_1      3732 non-null float64\n",
      "attr3_1     3750 non-null float64\n",
      "sinc3_1     3750 non-null float64\n",
      "fun3_1      3750 non-null float64\n",
      "intel3_1    3750 non-null float64\n",
      "attr        3711 non-null float64\n",
      "sinc        3670 non-null float64\n",
      "intel       3666 non-null float64\n",
      "fun         3647 non-null float64\n",
      "met         3640 non-null float64\n",
      "iid         3808 non-null int64\n",
      "pid         3808 non-null int64\n",
      "shar1_1     3732 non-null float64\n",
      "dtypes: float64(53), int64(5), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print the data types.  We can see that there are three object variables, while the majority\n",
    "#  are floats, with 5 int variables: 'pid', 'iid', 'gender', 'match', and 'samerace'.\n",
    "#  I expain severall cells below why the object variables, 'pid', and 'iid'\n",
    "#  can be removed from the dataset before using it to fit our models. \n",
    "#  I also changed the remaining int variables to floats in the cell below so that the dataset\n",
    "#  would be easier to process by functions that we later use that require \n",
    "#  columns in a a pandas data frame to have the same type.\n",
    "\n",
    "df1.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['gender'] = pd.to_numeric(df1['gender'], downcast = 'float')\n",
    "df1['match'] = pd.to_numeric(df1['match'], downcast = 'float')\n",
    "df1['samerace'] = pd.to_numeric(df1['samerace'], downcast = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>match</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>...</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>met</th>\n",
       "      <th>iid</th>\n",
       "      <th>pid</th>\n",
       "      <th>shar1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3741.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3741.000000</td>\n",
       "      <td>3732.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3750.000000</td>\n",
       "      <td>3711.000000</td>\n",
       "      <td>3670.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "      <td>3647.000000</td>\n",
       "      <td>3640.000000</td>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3732.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.164916</td>\n",
       "      <td>0.344013</td>\n",
       "      <td>26.672815</td>\n",
       "      <td>2.885600</td>\n",
       "      <td>22.492333</td>\n",
       "      <td>17.740259</td>\n",
       "      <td>20.402589</td>\n",
       "      <td>17.191165</td>\n",
       "      <td>10.723025</td>\n",
       "      <td>...</td>\n",
       "      <td>7.671467</td>\n",
       "      <td>8.386667</td>\n",
       "      <td>6.274427</td>\n",
       "      <td>7.240736</td>\n",
       "      <td>7.421031</td>\n",
       "      <td>6.407595</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>281.451943</td>\n",
       "      <td>281.451943</td>\n",
       "      <td>11.599033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500066</td>\n",
       "      <td>0.371149</td>\n",
       "      <td>0.475107</td>\n",
       "      <td>3.847338</td>\n",
       "      <td>1.287227</td>\n",
       "      <td>11.968602</td>\n",
       "      <td>7.567328</td>\n",
       "      <td>7.267267</td>\n",
       "      <td>6.083094</td>\n",
       "      <td>6.288042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.581539</td>\n",
       "      <td>1.017758</td>\n",
       "      <td>1.955501</td>\n",
       "      <td>1.744989</td>\n",
       "      <td>1.509306</td>\n",
       "      <td>1.975880</td>\n",
       "      <td>0.879282</td>\n",
       "      <td>163.573517</td>\n",
       "      <td>163.573517</td>\n",
       "      <td>6.836312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender        match     samerace        age_o       race_o  \\\n",
       "count  3808.000000  3808.000000  3808.000000  3741.000000  3750.000000   \n",
       "mean      0.500000     0.164916     0.344013    26.672815     2.885600   \n",
       "std       0.500066     0.371149     0.475107     3.847338     1.287227   \n",
       "min       0.000000     0.000000     0.000000    18.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000    24.000000     2.000000   \n",
       "50%       0.500000     0.000000     0.000000    26.000000     2.000000   \n",
       "75%       1.000000     0.000000     1.000000    29.000000     4.000000   \n",
       "max       1.000000     1.000000     1.000000    55.000000     6.000000   \n",
       "\n",
       "          pf_o_att     pf_o_sin     pf_o_int     pf_o_fun     pf_o_amb  ...  \\\n",
       "count  3750.000000  3750.000000  3750.000000  3741.000000  3732.000000  ...   \n",
       "mean     22.492333    17.740259    20.402589    17.191165    10.723025  ...   \n",
       "std      11.968602     7.567328     7.267267     6.083094     6.288042  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%      15.000000    15.000000    16.000000    14.000000     5.000000  ...   \n",
       "50%      20.000000    19.000000    20.000000    18.000000    10.000000  ...   \n",
       "75%      25.000000    20.000000    25.000000    20.000000    15.000000  ...   \n",
       "max      80.000000    60.000000    50.000000    50.000000    53.000000  ...   \n",
       "\n",
       "            fun3_1     intel3_1         attr         sinc        intel  \\\n",
       "count  3750.000000  3750.000000  3711.000000  3670.000000  3666.000000   \n",
       "mean      7.671467     8.386667     6.274427     7.240736     7.421031   \n",
       "std       1.581539     1.017758     1.955501     1.744989     1.509306   \n",
       "min       2.000000     5.000000     0.000000     0.000000     0.000000   \n",
       "25%       7.000000     8.000000     5.000000     6.000000     7.000000   \n",
       "50%       8.000000     8.000000     6.000000     7.000000     7.000000   \n",
       "75%       9.000000     9.000000     8.000000     8.000000     8.000000   \n",
       "max      10.000000    10.000000    10.000000    10.000000    10.000000   \n",
       "\n",
       "               fun          met          iid          pid      shar1_1  \n",
       "count  3647.000000  3640.000000  3808.000000  3808.000000  3732.000000  \n",
       "mean      6.407595     0.553846   281.451943   281.451943    11.599033  \n",
       "std       1.975880     0.879282   163.573517   163.573517     6.836312  \n",
       "min       0.000000     0.000000     1.000000     1.000000   -28.000000  \n",
       "25%       5.000000     0.000000   129.000000   129.000000     8.000000  \n",
       "50%       7.000000     0.000000   288.000000   288.000000    10.000000  \n",
       "75%       8.000000     2.000000   434.000000   434.000000    15.000000  \n",
       "max      10.000000     5.000000   550.000000   550.000000    30.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of the data\n",
    "df1.describe()\n",
    "\n",
    "# Looking at the summary, we can pull out a few important points.  The average age of the\n",
    "#  participants was around 27, about 16.5% of participants found matches, and \n",
    "#  subjects had the highest bar for attractiveness out of all other characteristics when\n",
    "#  it comes to finding a partner (mean of pf_o_att was the highest out of all the preference\n",
    "#  variables at about 22.5).  After meeting their partners, on average, people rated\n",
    "#  the intelligence of their partner as their partner's highest scoring characteristic, \n",
    "#  followed by sincerity (means of 7.4 and 7.2 respectively.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pf_o_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>19.605966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>21.206897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pf_o_int\n",
       "gender           \n",
       "0.0     19.605966\n",
       "1.0     21.206897"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The paper on the speed dating study focused on gender differences, so I thought it\n",
    "#  would be interesting to see if certain partner preferences differed by gender in \n",
    "#  the cells below:\n",
    "\n",
    "# Did a certain gender have preference for a partner with higher \n",
    "#  intelligence?\n",
    "gender_int_pref = pd.DataFrame(df1.groupby('gender')['pf_o_int'].mean())\n",
    "gender_int_pref.head()\n",
    "\n",
    "# We can see that the average preference for intelligence was not much different among\n",
    "#  men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pf_o_amb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>8.514609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>12.931442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pf_o_amb\n",
       "gender           \n",
       "0.0      8.514609\n",
       "1.0     12.931442"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Did a certain gender have preference for a partner with higher \n",
    "#  ambition?\n",
    "gender_amb_pref = pd.DataFrame(df1.groupby('gender')['pf_o_amb'].mean())\n",
    "gender_amb_pref.head()\n",
    "\n",
    "# We can see that women on average prefer partner's with a higher level of ambition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pf_o_att</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>27.743195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17.190820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pf_o_att\n",
       "gender           \n",
       "0.0     27.743195\n",
       "1.0     17.190820"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Did a certain gender have preference for a partner with higher \n",
    "#  attractiveness?\n",
    "gender_att_pref = pd.DataFrame(df1.groupby('gender')['pf_o_att'].mean())\n",
    "gender_att_pref.head()\n",
    "\n",
    "# As stated in the study, we can see that men on average want their partner to be much\n",
    "#  more attractive than women do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-68378432233c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mafr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mafr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mafr_race\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imprace'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imprace'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafr_race\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Importance of race for African Americans\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Importance of Race'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's look at the importance of having a partner of the same race for each of \n",
    "#  the different ethnicity groups.\n",
    "\n",
    "afr = (df1['race']==1)\n",
    "afr = df1[afr]\n",
    "afr_race = afr[np.isfinite(afr['imprace'])]['imprace']\n",
    "plt.hist(afr_race)\n",
    "plt.title(\"Importance of race for African Americans\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur = (df1['race']==2)\n",
    "eur = df1[eur]\n",
    "eur_race = eur[np.isfinite(eur['imprace'])]['imprace']\n",
    "plt.hist(eur_race)\n",
    "plt.title(\"Importance of race for European/Caucasian-Americans\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = (df1['race']==3)\n",
    "lat = df1[lat]\n",
    "lat_race = lat[np.isfinite(lat['imprace'])]['imprace']\n",
    "plt.hist(lat_race)\n",
    "plt.title(\"Importance of Race for Latinos\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asi = (df1['race']==4)\n",
    "asi = df1[asi]\n",
    "asi_race = asi[np.isfinite(asi['imprace'])]['imprace']\n",
    "plt.hist(asi_race)\n",
    "plt.title(\"Importance of Race for Asian Americans\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = (df1['race']==5)\n",
    "nat = df1[nat]\n",
    "nat_race = nat[np.isfinite(nat['imprace'])]['imprace']\n",
    "plt.hist(nat_race)\n",
    "plt.title(\"Importance of race for Native Americans\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oth = (df1['race']==6)\n",
    "oth = df1[oth]\n",
    "oth_race = oth[np.isfinite(oth['imprace'])]['imprace']\n",
    "plt.hist(oth_race)\n",
    "plt.title(\"Importance of race for 'Other' group\")\n",
    "plt.xlabel('Importance of Race')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "#  We can see that the study did not include any Native American participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all ethnicities, we can see that their partner being the same race as them is \n",
    "#  fairly important (1) for around half the of the participants in that ethnicity group, \n",
    "#  while the rest of the people in that group have preferences that vary from 2 all the way\n",
    "#  to 10 for some groups.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I want to use scatterplots to see how the importance of pairs of attributes looked\n",
    "#  for in a partner correlate together.  For example, do most people who care a\n",
    "#  lot about attractiveness also care a lot about intelligence?\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "sns_df = df1[['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']]\n",
    "sns.pairplot(sns_df)\n",
    "\n",
    "# We can see from the scatterplots below that there are no particularly strong correlations\n",
    "#  between the importance of different characteristics that a partner looks for.  Visually,\n",
    "#  the strongest relationship seems to be between intel1_1 and fun1_1, meaning that partners\n",
    "#  who look for people who are a lot of fun also want that person to be very intelligent \n",
    "#  and vice versa. Alternatively, we could say that people who do not care about \n",
    "#  their partner being fun also don't care very\n",
    "#  much about their partner being inteligent (amongst the other variables they were asked \n",
    "#  about), though this latter scenario is unlikely. Also, intelligence and sincerity seem \n",
    "#  to have the next strongest (though still weak) correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>match</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun_o</th>\n",
       "      <td>2.961235e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>2.961235e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr_o</th>\n",
       "      <td>2.591713e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr</th>\n",
       "      <td>2.591713e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel_o</th>\n",
       "      <td>1.918684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel</th>\n",
       "      <td>1.918684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc</th>\n",
       "      <td>1.872059e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc_o</th>\n",
       "      <td>1.872059e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met</th>\n",
       "      <td>6.920998e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_fun</th>\n",
       "      <td>6.118950e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun1_1</th>\n",
       "      <td>6.118950e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun3_1</th>\n",
       "      <td>5.512889e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yoga</th>\n",
       "      <td>3.770946e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <td>3.603735e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iid</th>\n",
       "      <td>3.603735e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerts</th>\n",
       "      <td>3.097094e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_int</th>\n",
       "      <td>2.932431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel1_1</th>\n",
       "      <td>2.932431e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>2.827612e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr3_1</th>\n",
       "      <td>2.818462e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reading</th>\n",
       "      <td>2.692156e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel3_1</th>\n",
       "      <td>2.349606e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>2.279281e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samerace</th>\n",
       "      <td>2.079504e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clubbing</th>\n",
       "      <td>1.501809e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theater</th>\n",
       "      <td>1.186781e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc3_1</th>\n",
       "      <td>1.101460e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>museums</th>\n",
       "      <td>8.237209e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>6.681062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>5.362012e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiking</th>\n",
       "      <td>3.403386e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-3.708163e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <td>-2.341748e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvsports</th>\n",
       "      <td>-4.418242e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_o</th>\n",
       "      <td>-5.396392e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>-5.396392e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_att</th>\n",
       "      <td>-7.601741e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr1_1</th>\n",
       "      <td>-7.601741e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_amb</th>\n",
       "      <td>-9.339765e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb1_1</th>\n",
       "      <td>-9.339765e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dining</th>\n",
       "      <td>-1.091041e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imprelig</th>\n",
       "      <td>-1.330196e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopping</th>\n",
       "      <td>-1.893142e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>-2.116659e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc1_1</th>\n",
       "      <td>-2.465039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_sin</th>\n",
       "      <td>-2.465039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>-2.828756e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar1_1</th>\n",
       "      <td>-3.076149e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career_c</th>\n",
       "      <td>-3.429688e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imprace</th>\n",
       "      <td>-3.928824e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>-4.184501e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pf_o_sha</th>\n",
       "      <td>-4.762809e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_o</th>\n",
       "      <td>-5.762642e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-5.762642e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>-6.978096e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go_out</th>\n",
       "      <td>-7.210557e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_o</th>\n",
       "      <td>-1.237970e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Correlation\n",
       "match     1.000000e+00\n",
       "fun_o     2.961235e-01\n",
       "fun       2.961235e-01\n",
       "attr_o    2.591713e-01\n",
       "attr      2.591713e-01\n",
       "intel_o   1.918684e-01\n",
       "intel     1.918684e-01\n",
       "sinc      1.872059e-01\n",
       "sinc_o    1.872059e-01\n",
       "met       6.920998e-02\n",
       "pf_o_fun  6.118950e-02\n",
       "fun1_1    6.118950e-02\n",
       "fun3_1    5.512889e-02\n",
       "yoga      3.770946e-02\n",
       "pid       3.603735e-02\n",
       "iid       3.603735e-02\n",
       "concerts  3.097094e-02\n",
       "pf_o_int  2.932431e-02\n",
       "intel1_1  2.932431e-02\n",
       "music     2.827612e-02\n",
       "attr3_1   2.818462e-02\n",
       "reading   2.692156e-02\n",
       "intel3_1  2.349606e-02\n",
       "art       2.279281e-02\n",
       "samerace  2.079504e-02\n",
       "clubbing  1.501809e-02\n",
       "theater   1.186781e-02\n",
       "sinc3_1   1.101460e-02\n",
       "museums   8.237209e-03\n",
       "sports    6.681062e-03\n",
       "gaming    5.362012e-03\n",
       "hiking    3.403386e-03\n",
       "gender   -3.708163e-17\n",
       "exercise -2.341748e-03\n",
       "tvsports -4.418242e-03\n",
       "race_o   -5.396392e-03\n",
       "race     -5.396392e-03\n",
       "pf_o_att -7.601741e-03\n",
       "attr1_1  -7.601741e-03\n",
       "pf_o_amb -9.339765e-03\n",
       "amb1_1   -9.339765e-03\n",
       "dining   -1.091041e-02\n",
       "imprelig -1.330196e-02\n",
       "shopping -1.893142e-02\n",
       "tv       -2.116659e-02\n",
       "sinc1_1  -2.465039e-02\n",
       "pf_o_sin -2.465039e-02\n",
       "goal     -2.828756e-02\n",
       "shar1_1  -3.076149e-02\n",
       "career_c -3.429688e-02\n",
       "imprace  -3.928824e-02\n",
       "movies   -4.184501e-02\n",
       "pf_o_sha -4.762809e-02\n",
       "age_o    -5.762642e-02\n",
       "age      -5.762642e-02\n",
       "date     -6.978096e-02\n",
       "go_out   -7.210557e-02\n",
       "met_o    -1.237970e-01"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find correlations of each variable to the 'match' target variable\n",
    "matchornot=df1['match']\n",
    "similar_to_match = df1.corrwith(matchornot)\n",
    "corr_match = pd.DataFrame(similar_to_match, columns=['Correlation'])\n",
    "corr_match.dropna(inplace=True)\n",
    "corr_match=corr_match.sort_values(by = 'Correlation', ascending=False)\n",
    "corr_match\n",
    "\n",
    "# We can see that a partner being fun, and attractive (as rated by their partner) are\n",
    "#  the most (positively) correlated with being a match.  A partner being attractive (again as \n",
    "#  rated by their partner) is the third most correlated variable, followed by intelligence \n",
    "#  and sincerity. On the negative end, we can see that the variable 'met_o' has the strongest\n",
    "#  negative correlation which match, meaning that if a partner has met the person before, they\n",
    "#  are less likely to be a match.  We can see from the rest of the correlations below that \n",
    "#  the rest of the variables are one order of magnitude less strongly\n",
    "#  correlated than the variables just listed, so they may not \n",
    "#  be as useful features to include in a model predicting a match.  Nevertheless, I decided\n",
    "#  to keep them as variables when developing my models using grid search since they may \n",
    "#  provide some value. It is important to note that all these corelations are relatively weak\n",
    "#  correlations as they are all less than .5, or on the negative end, greater than -.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  counts\n",
       "match        \n",
       "0.0      3180\n",
       "1.0       628"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of different match values\n",
    "\n",
    "pd.crosstab(index=df1['match'], columns='counts')\n",
    "\n",
    "# We can see that there are far more non-matches than matches.  This may affect how our\n",
    "#  models make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'from' column seems like it could potentially contain too many \n",
    "#  (or an infinite number of) different possible\n",
    "#  entries, since the study participants wrote in their own answer choices and thus the \n",
    "#  'from' variable would not be very useful in predicting match. Because of this, I \n",
    "#  decided to check the number of unique values in the 'from' column.\n",
    "df1['from'].nunique()\n",
    "\n",
    "# Since there are 154 unique values, and for the reason I stated above, it would be \n",
    "#  reasonable to exclude the 'from' from the datset due to its infinite nature (especially\n",
    "#  if we would be testing our potential model on a completely new dataset that could\n",
    "#  contain even more unique 'from' values), so I will remove it in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a63c275cf683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#  in the cells below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'match'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"career\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"field\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "# Before creating the training and split sets, I removed all the NA values from the dataset\n",
    "#  to have more accurate data to work with.  I also dropped the 'career' and 'field' columns\n",
    "#  from the dataset because they each have a corresponding numerically coded variable \n",
    "#  (career_c and field_c), so it would be unnecessary to keep the original string variables.\n",
    "#  I dropped 'iid' and 'pid' also because they are random number assigned to study \n",
    "#  participants and will not be meaningul predictors. \n",
    "#  Since I will be running a chi-square test for feature selection, which cannot handle\n",
    "#  negative values, I removed all rows of the dataset with at least one column\n",
    "#  containing a negative value. At the end of all of this, I was left with 3169 rows from\n",
    "#  the original 3808.\n",
    "#  I then created two different dataframes, one with the predictors, and one with the target\n",
    "#  variable.  This separation of variables is done so that I can perform feature selection\n",
    "#  in the cells below.\n",
    "\n",
    "df1 = df1.dropna()\n",
    "df1 = df1.dropna(subset=['match'])\n",
    "df1 = df1.drop(columns = [\"career\", \"field\", 'from', 'iid', 'pid'])\n",
    "#df1 = df1[df1 > 0].dropna()\n",
    "for cols in df1.columns.tolist()[1:]:\n",
    "    df1 = df1.ix[df1[cols] >= 0]\n",
    "print(\"length of dataset after removing negative values:\"),\n",
    "print(len(df1))\n",
    "\n",
    "# I removed outliers using the following method:\n",
    "#  For each row, calculate the z score for each column, and then filter out \n",
    "#  rows of the dataset, so that if a row has at least one column whose z score value \n",
    "#  is above 3 or below 3, then it is considered an outlier, and that row is removed \n",
    "#  from the dataset.\n",
    "\n",
    "from scipy import stats\n",
    "df1 = df1[(np.abs(stats.zscore(df1)) < 3).all(axis=1)]\n",
    "\n",
    "print(\"length of dataset after removing outlier:\"),\n",
    "print(len(df1))\n",
    "\n",
    "X = df1[['gender', 'samerace', 'age_o', 'race_o', 'pf_o_att',\n",
    "       'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o',\n",
    "       'sinc_o', 'intel_o', 'fun_o', 'met_o', 'age', 'race',\n",
    "       'imprace', 'imprelig', 'goal', 'date', 'go_out',\n",
    "       'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums',\n",
    "       'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',\n",
    "       'movies', 'concerts', 'music', 'shopping', 'yoga', 'attr1_1', 'sinc1_1',\n",
    "       'intel1_1', 'fun1_1', 'amb1_1', 'attr3_1', 'sinc3_1', 'fun3_1',\n",
    "       'intel3_1', 'attr', 'sinc', 'intel', 'fun', 'met', 'shar1_1']]\n",
    "y = df1['match']\n",
    "\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Specs       Score\n",
      "52     fun  115.784273\n",
      "13   fun_o  106.724705\n",
      "49    attr   86.939867\n",
      "10  attr_o   85.019178\n",
      "50    sinc   33.883137\n"
     ]
    }
   ],
   "source": [
    "# Feature selection \n",
    "\n",
    "# I used a chi-square test to find the top 5 most important features, in other words, the\n",
    "#  features which are most dependent to our target variable 'match'.  These are variables\n",
    "#  which have the highest chi-square value, indicating a lack of independence.  I printed\n",
    "#  a list of the top 5 features below.\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)  \n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score'] \n",
    "print(featureScores.nlargest(5,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00630621 0.01532755 0.03131109 0.02414011 0.02536118 0.02939525\n",
      " 0.02483449 0.02838056 0.02518885 0.02792951 0.04909528 0.03317845\n",
      " 0.02910709 0.0594933  0.         0.01196782 0.00908939 0.01129317\n",
      " 0.01274495 0.0113899  0.01486078 0.0122679  0.01286946 0.010621\n",
      " 0.01302303 0.01198124 0.01028087 0.01107056 0.00936627 0.01107223\n",
      " 0.01314887 0.01529452 0.0108257  0.01183978 0.00849432 0.01471262\n",
      " 0.01403257 0.00910464 0.01104987 0.01016323 0.01260067 0.01423178\n",
      " 0.0109678  0.01017171 0.00990591 0.00869934 0.0119323  0.01410735\n",
      " 0.00885488 0.05196705 0.03420102 0.02396262 0.06615719 0.01121112\n",
      " 0.00941563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, I also used an extremely randomized trees classifier to select the important\n",
    "#  features of our dataset.  This python function creates 10 (default number) trees\n",
    "#  and provides each tree with a unique random sample of the dataset features.  The trees\n",
    "#  then calculate their own gini index (default) and each come up with the top features.\n",
    "#  The average result of all these trees is taken to provide the final list of most \n",
    "#  useful features.  The 5 most important features are displayed in the bar graph below. \n",
    "#  It is important to note that the top 4 features here agree with the top 4 \n",
    "#  features chosen by the chi-square method above.  The only difference in results is\n",
    "#  that the chi-square method chose 'sinc' as a top five important feature and \n",
    "#  extremely randomized trees chose 'intel-o'.\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next I used a heat map to visualize the correlations between the top 5 most important\n",
    "#  features (as chosen by the extremely randomized trees classifier) and the target variable.\n",
    "import seaborn as sns\n",
    "data = df1[['sinc',\n",
    " 'attr_o',\n",
    " 'attr',\n",
    " 'fun_o','fun','match']]\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "\n",
    "# We can see that the strongest correlations are between 'fun' and 'attr',\n",
    "#  'fun_o' and 'attr_o', both at .55 .  More importantly, the strongest\n",
    "#  correlation between match and the one of top five most important variables is \n",
    "#  the variable 'fun', with a correlation of .31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Despite my results from the two feature selection methods, \n",
    "#  I decided to keep the remaining variables as predictors\n",
    "#  as they could potentially add some value.\n",
    "\n",
    "# In preparation for building models in part 2, I split up our dataset into a training\n",
    "#  and testing set.  I chose to have 75% of the data in the training set (default value),\n",
    "#  as including more data in the training set usually leads to stronger, more accurate models.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Predicting Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For part 2, I built 4 different models: a random forest classifier, a logistic regression,\n",
    "#  a support vector machine, and a multi-layer perceptron.  My method for constructing each\n",
    "#  model is as follows:\n",
    "#  I used the grid search method to pick the best parameters for the relevant model, based\n",
    "#  on the training set I created above (X/y_train). The GridSearchCV function took my \n",
    "#  training set and split it up into 5 different validation sets.  I chose\n",
    "#  5 as the number of folds as this has been empirically shown to be \n",
    "#  a reasonable value that will balance out the variance-bias tradeoff inherent\n",
    "#  in the cross-validation method.  This 5-fold cross\n",
    "#  validation procedure built the specified model type 5 times, each time using one of the\n",
    "#  five validation sets as a test set, and the rest of the 4 validation sets as training\n",
    "#  sets to fit the model. The performance (weighted f-score, a weighted average\n",
    "#  of precision and recall) of all these 5 models \n",
    "#  was then averaged to give the final weighted f-score of the model. The advantage to using\n",
    "#  cross-validation over simply having a training and testing set is that there is always\n",
    "#  a tradeoff between placing points in one of the two sets (overfitting when placing \n",
    "#  too many points in the training set and underfitting when placing too many points in \n",
    "#  the testing set).  However, with cross validation, each data point has the opportunity\n",
    "#  to both be in the training and testing set.\n",
    "#  After running the GridSearchCV function for the specified model type,\n",
    "#  I could then see the best parameter values for each parameter\n",
    "#  and the corresponding weighted f-score.  I used these parameter  \n",
    "#  values to build the actual model, again fit on the training set.   \n",
    "#  I then predicted target values for my test set (X/y_test) and used these values along\n",
    "#  with the test set's actual values to compute the weighted f-score.  \n",
    "#  I chose to use a separate testing set on top of using \n",
    "#  cross-validation because sometimes cross-validation may overestimate the performance \n",
    "#  of a model due to the nature of its averaging of f-scores, \n",
    "#  so using a separate testing set as a way to evaluate the model may \n",
    "#  give a better sense of the model's true performace.\n",
    "#  \n",
    "#  I used this final weighted f-score to evaluate the model's\n",
    "#  performance against those of the other model types:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'n_estimators': 100}\n",
      "0.8111476728325915\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "# First tune model with grid searching and cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 30, 70, 100],\n",
    "    'max_depth':[10,20,30]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5,scoring='f1_weighted')  # be careful about scoring, always match\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)\n",
    "print(CV_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8455813363258982\n"
     ]
    }
   ],
   "source": [
    "# Now use the parameters found above to create the random forest classifier:\n",
    "from sklearn.metrics import f1_score\n",
    "rfc = RandomForestClassifier(max_depth=30, n_estimators= 100) \n",
    "rfc.fit(X_train, y_train)\n",
    "result_y = rfc.predict(X_test)\n",
    "print(\"f1 score:\", f1_score(y_test, result_y, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "0.8240895729867201\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "# First tune model with grid searching and cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression() \n",
    "\n",
    "param_grid = { \n",
    "    'C': [0.001,0.01,0.1,1,10,100],\n",
    "    \"penalty\":[\"l1\",\"l2\"]\n",
    "}\n",
    "\n",
    "CV_lg = GridSearchCV(estimator=lg, param_grid=param_grid, cv= 5,scoring='f1_weighted')  # be careful about scoring, always match\n",
    "CV_lg.fit(X_train, y_train)\n",
    "print(CV_lg.best_params_)\n",
    "print(CV_lg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8274997622544618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Now use the parameters found above to create the logistic regression model\n",
    "from sklearn.metrics import f1_score\n",
    "lg = LogisticRegression(C= 1, penalty= 'l2') \n",
    "lg.fit(X_train, y_train)\n",
    "result_y = lg.predict(X_test)\n",
    "print(\"f1 score:\", f1_score( y_test, result_y, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-da720fd1fabd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mCV_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mCV_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV_lasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 98\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Lasso Regression - I attempted to run a lasso regression but ran into an error:\n",
    "#  'ValueError: Classification metrics can't handle a mix of binary and continuous targets'.\n",
    "#  I then looked into the python documentation and noticed that Lasso() is implemented as \n",
    "#  a regression rather than classification model, thus given that our match column is binary\n",
    "#  and we are trying to solve a classification problem, the Lasso() function from sklearn \n",
    "#  could not be used in our case, unless I missed finding the parameter or other model\n",
    "#  specifications in my online search that would allow this function to work for our problem.\n",
    "\n",
    "# First tune model with grid searching and cross validation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import Lasso\n",
    "# lasso = Lasso() \n",
    "\n",
    "# param_grid = { \n",
    "#     'alpha': [0.001,0.01,0.1,1,10,100]\n",
    "# }\n",
    "\n",
    "\n",
    "# CV_lasso = GridSearchCV(estimator=lasso, param_grid=param_grid, cv= 5,scoring='f1_weighted')  \n",
    "# CV_lasso.fit(X_train, y_train)\n",
    "# print(CV_lasso.best_params_)\n",
    "# print(CV_lasso.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dorsamassihpour/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.8224400271506651\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "# First tune model with grid searching and cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC() \n",
    "\n",
    "param_grid = { \n",
    "    'gamma': [0.001, .1, 1, 10], \n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.001, .1, 1, 10] \n",
    "}\n",
    "\n",
    "\n",
    "CV_svc = GridSearchCV(estimator=svc, param_grid=param_grid, cv= 5,scoring='f1_weighted')  # be careful about scoring, always match\n",
    "CV_svc.fit(X_train, y_train)\n",
    "print(CV_svc.best_params_)\n",
    "print(CV_svc.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8406097473307294\n"
     ]
    }
   ],
   "source": [
    "# Now use the parameters found above to create the svm\n",
    "from sklearn.metrics import f1_score\n",
    "svc = SVC(C=10, gamma= .001, kernel = 'rbf') \n",
    "svc.fit(X_train, y_train)\n",
    "result_y = svc.predict(X_test)\n",
    "print(\"f1 score:\", f1_score(y_test, result_y, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'alpha': 10, 'solver': 'lbfgs'}\n",
      "0.8126767426944168\n"
     ]
    }
   ],
   "source": [
    "# Multi-layer perceptron\n",
    "\n",
    "# First tune model with grid searching and cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier() \n",
    "\n",
    "# param_grid = { \n",
    "#     'hidden_layer_sizes': [(100, 100, 100)],\n",
    "#     'activation':[\"identity\",\"logistic\", \"tanh\", \"relu\"],\n",
    "#     'solver':[â€˜lbfgsâ€™, â€˜sgdâ€™],\n",
    "#     'alpha':[0.001,0.01,0.1,1,10],\n",
    "#     'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "    \n",
    "# }\n",
    "\n",
    "param_grid = { \n",
    "    'activation':[\"identity\",\"logistic\"],\n",
    "    'solver':['lbfgs', 'sgd'],\n",
    "    'alpha':[0.001,.01,1,10]\n",
    "}\n",
    "\n",
    "CV_mlp = GridSearchCV(estimator=mlp, param_grid=param_grid, cv= 5,scoring='f1_weighted')\n",
    "CV_mlp.fit(X_train, y_train)\n",
    "print(CV_mlp.best_params_)\n",
    "print(CV_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.8605495999835904\n"
     ]
    }
   ],
   "source": [
    "# Now use the parameters found above to create the perceptron\n",
    "from sklearn.metrics import f1_score\n",
    "mlp = MLPClassifier(activation = 'logistic', alpha = 10, solver = 'lbfgs')  \n",
    "mlp.fit(X_train, y_train)\n",
    "result_y = mlp.predict(X_test)\n",
    "print(\"f1 score:\", f1_score(y_test, result_y, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the weighted f-score of all 4 models evaluated on the separate testing set,\n",
    "#  the multi-layer perceptron had the highest score at abou 0.853, with the random forest \n",
    "#  classifier as the second best, with a weighted f-score of about 0.846.  (The higher\n",
    "#  the f-score, the better the precision and recall of the model, or the higher the\n",
    "#  proportion of true positives over the combination of true and false positives, and the \n",
    "#  proportion of true positives over the combination of true positives and false negatives\n",
    "#  , respectively.) ***\n",
    "#  Thus, I chose the multi-layer perceptron as the final model to predict the match column for the\n",
    "#  'testML.csv' data.  \n",
    "\n",
    "# *** Citation: \n",
    "#   Saxena, Shruti. â€œPrecision vs Recall.â€ Medium, Towards Data Science, 13 May 2018, \n",
    "#     https://towardsdatascience.com/precision-vs-recall-386cf9f89488.\n",
    "\n",
    "# In order the make predictions in the 'testML.csv' dataset, I had to make a few modifications\n",
    "#  to the dataset.  First, I replaced all NAN entries with a 0.  This seemed like \n",
    "#  a reasonable substitution given that if there should be a high rating/value for one \n",
    "#  of the variables, the subject would have most likely seen it as important to answer \n",
    "#  rather than leave blank.  Next, I removed the columns that I had removed in the \n",
    "#  corresponding 'trainML.csv' dataset: career, field, from, iid, and pid.  I also \n",
    "#  removed the 'shar1_1' column, as this column was not present in 'trainML.csv' and thus\n",
    "#  we could not use it as a predictor in the perceptron model we had built.\n",
    "#df2 = df2.drop(columns = [\"career\", \"field\", 'from', 'iid', 'pid', 'shar1_1'])\n",
    "\n",
    "# I saved the result of the predictions (numpy array) into a separate csv file and copied\n",
    "#  the contents to the 'match' column of 'testML.csv'\n",
    "df2 = df2.fillna(0)\n",
    "predictions_for_testML_data = mlp.predict(df2.iloc[:, 0:55])\n",
    "\n",
    "np.savetxt(\"hw1_predictions_part2.csv\", predictions_for_testML_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# For part 3, I built and compared 4 different recommendation engines based on\n",
    "#  different algorithms: KNN with means (K-means), singular vector decomposition,\n",
    "#  SVD++, and non-negative matrix factorization (NMF). After reading in the data and\n",
    "#  specifying the proper rating, I used the surprise package's GridSearchCV function \n",
    "#  to find the parameters that provided the lowest mean absolute error \n",
    "#  for each model.  I supplied\n",
    "#  the grid search function with a variety of the top 2 or 3 important parameters\n",
    "#  and again chose k =5 for the same reason as in part 2.\n",
    "#  The grid search method (as with the corresponding sklearn method used in part 2)\n",
    "#  divided the dataset into 5 different dataset and ran the model 5 times using \n",
    "#  one of the five datasets as the testing set and the four others as a combined training \n",
    "#  set each time.  After fitting on that iteration's training set, it then calculated the \n",
    "#  mean absolute error (mae), and averaged over all five iterations to give the final \n",
    "#  mae outputed by the best_score function.  I then picked the model with the \n",
    "#  lowest mae and predicted the 'rate' column for the 'testRec.csv' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.dataset.DatasetAutoFolds'>\n"
     ]
    }
   ],
   "source": [
    "# Define the rate\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "# Read data and split into training and test dataset\n",
    "data = Dataset.load_from_df(df3[[\"pid\", \"iid\", \"rate\"]], reader)\n",
    "from surprise.model_selection import train_test_split\n",
    "#trainingSet, testingSet = train_test_split(data, test_size = .25)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "{'mae': {'k': 5, 'sim_options': {'name': 'cosine', 'user_based': True}}}\n",
      "{'mae': 0.09197182663924368}\n"
     ]
    }
   ],
   "source": [
    "# KNN algorithm\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "algo = KNNWithMeans\n",
    "#trainingSet = data.build_full_trainset()\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'k': [5,10,20,50,100],\n",
    "    'sim_options': {'name': ['cosine', 'msd'], 'user_based': [False, True]}\n",
    "}\n",
    "\n",
    "CV_knn = GridSearchCV(algo_class=algo, param_grid=param_grid, cv= 5, measures=['mae'])\n",
    "CV_knn.fit(data)\n",
    "print(CV_knn.best_params)\n",
    "print(CV_knn.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': {'n_factors': 100, 'n_epochs': 30, 'lr_all': 0.01}}\n",
      "{'mae': 0.08411962739450378}\n"
     ]
    }
   ],
   "source": [
    "# SVD\n",
    "from surprise import SVD\n",
    "\n",
    "# grid search\n",
    "\n",
    "param_grid = { \n",
    "    'n_factors': [10,20,50,100],\n",
    "    'n_epochs': [20,30],\n",
    "    #, init_mean :[0,10,100], init_std_dev:[.1,1.10], \n",
    "    'lr_all': [.001, .01]\n",
    "}\n",
    "\n",
    "algo = SVD\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "CV_svd = GridSearchCV(algo_class=algo, param_grid=param_grid, cv= 5, measures=['mae']) \n",
    "CV_svd.fit(data)\n",
    "print(CV_svd.best_params)\n",
    "print(CV_svd.best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.01}}\n",
      "{'mae': 0.07986557908278058}\n"
     ]
    }
   ],
   "source": [
    "# SVD++ \n",
    "from surprise import SVDpp\n",
    "\n",
    "# grid search\n",
    "param_grid = { \n",
    "    'n_factors': [10, 50],\n",
    "    'n_epochs': [20,30], \n",
    "    #, init_mean :[0,10,100], init_std_dev:[.1,1.10], \n",
    "    'lr_all':[.001, .01]}\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "CV_svdpp = GridSearchCV(algo_class = SVDpp, param_grid = param_grid, cv = 5, measures=['mae'])\n",
    "CV_svdpp.fit(data)\n",
    "print(CV_svdpp.best_params)\n",
    "print(CV_svdpp.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': {'n_factors': 20, 'n_epochs': 100}}\n",
      "{'mae': 0.2556044337057573}\n"
     ]
    }
   ],
   "source": [
    "# NMF\n",
    "from surprise import NMF\n",
    "\n",
    "# grid search\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_factors': [1,10,20, 50,100],\n",
    "    'n_epochs': [1,10,20,50,100]  \n",
    "    #, 'reg_pu': [0.001, .06, .1, 1, 10],\n",
    "    # 'reg_qi': [0.001, .02, .1, 1, 10],\n",
    "    # 'reg_bu': [0.0001, .001, .1, 1], 10,\n",
    "    # 'Ir_bi': [0.001, .005, .01, .1, 1, 10],\n",
    "}\n",
    "\n",
    "CV_nmf = GridSearchCV(NMF, param_grid=param_grid, measures=['mae'], cv= 5)\n",
    "CV_nmf.fit(data)\n",
    "print(CV_nmf.best_params)\n",
    "print(CV_nmf.best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# We can see from the 4 mae scores above that the best model type is the \n",
    "# SVD++ estimator, with the lowest mae of about.080.  The parameters that give this mae\n",
    "#  score are 50 factors, 30 iterations of the SGD procedure, and a learning\n",
    "#  rate of .01 for all parametersclusters.  I used these parameters to build\n",
    "#  the final SVD++ model, predicted the 'rate' column for the 'testRec.csv' file \n",
    "#  (test function), and saved the results to a separate\n",
    "#  csv before copying it over to the test file\n",
    "\n",
    "\n",
    "#Output from above:\n",
    "#{'mae': {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.01}}\n",
    "#{'mae': 0.07986557908278058}\n",
    "\n",
    "trainingSet = data.build_full_trainset()\n",
    "my_svdpp = SVDpp(n_factors=50, n_epochs=30, lr_all=0.01)  \n",
    "my_svdpp.fit(trainingSet)\n",
    "\n",
    "list_of_predicted_ratings = []\n",
    "for ind in df4.index:\n",
    "    curr_elem = my_svdpp.predict(df4['pid'][ind], df4['iid'][ind])\n",
    "    curr_elem = curr_elem.est\n",
    "    list_of_predicted_ratings.append(curr_elem)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.306795906132861,\n",
       " 7.26015102418811,\n",
       " 6.404723304881439,\n",
       " 7.197902557273127,\n",
       " 6.888264416178088,\n",
       " 6.671771164744209,\n",
       " 6.7874253050514,\n",
       " 6.413713141069442,\n",
       " 6.933589830607236,\n",
       " 5.514289273647438,\n",
       " 7.2609403444621154,\n",
       " 7.24644360158159,\n",
       " 7.38234053753839,\n",
       " 7.546837942962609,\n",
       " 6.661111509846253,\n",
       " 7.519408621498314,\n",
       " 7.44422294142253,\n",
       " 6.705522995976446,\n",
       " 7.441931221004733,\n",
       " 7.580922624350682,\n",
       " 7.7667677674207285,\n",
       " 6.50299564367317,\n",
       " 7.379538073137067,\n",
       " 7.56787311649239,\n",
       " 7.443511686746054,\n",
       " 6.168887085996596,\n",
       " 7.04451056502247,\n",
       " 7.1550863144138175,\n",
       " 7.005860807515847,\n",
       " 6.942826811814195,\n",
       " 7.2339638049356205,\n",
       " 7.363680180186612,\n",
       " 8.293283428622539,\n",
       " 6.130983620478451,\n",
       " 6.823356516728424,\n",
       " 6.933284663087142,\n",
       " 6.434700342623525,\n",
       " 6.354236755504785,\n",
       " 6.833387926859094,\n",
       " 6.696715630643084,\n",
       " 7.019437156914437,\n",
       " 6.954284047746365,\n",
       " 7.337178121618856,\n",
       " 7.599175095978007,\n",
       " 6.92710711290256,\n",
       " 5.7114884260758485,\n",
       " 7.368077388580691,\n",
       " 6.676785280585902,\n",
       " 7.7997734837340165,\n",
       " 6.816492914861715,\n",
       " 7.553877655185023,\n",
       " 6.967230490435232,\n",
       " 8.299734266668551,\n",
       " 7.366608435747686,\n",
       " 7.617506970545502,\n",
       " 7.009537381056633,\n",
       " 6.49498002097904,\n",
       " 6.095468351026316,\n",
       " 6.498437583555058,\n",
       " 6.471027400512178,\n",
       " 7.307271448089184,\n",
       " 7.533475782457559,\n",
       " 6.675283206884883,\n",
       " 6.478031665868553,\n",
       " 6.898126160632853,\n",
       " 6.626991738063449,\n",
       " 7.9807973478264636,\n",
       " 6.780897946024891,\n",
       " 7.5392097684095045,\n",
       " 7.546683515430934,\n",
       " 7.220489071932005,\n",
       " 6.873458426572255,\n",
       " 6.99877518917171,\n",
       " 6.865669939781107,\n",
       " 6.805952250161941,\n",
       " 6.437956390457421,\n",
       " 6.415479845232504,\n",
       " 6.535261216019047,\n",
       " 7.385633669301684,\n",
       " 6.640475887160882,\n",
       " 7.13675498308832,\n",
       " 8.05387452184578,\n",
       " 7.522663167735916,\n",
       " 7.558640570999978,\n",
       " 6.469007314765976,\n",
       " 8.437153863623804,\n",
       " 5.815047538130113,\n",
       " 6.806271444275752,\n",
       " 7.614446960065094,\n",
       " 7.552431152850579,\n",
       " 7.5549625824473745,\n",
       " 6.286258142649987,\n",
       " 6.932325787972705,\n",
       " 8.041727725709666,\n",
       " 7.178419469996423,\n",
       " 7.493590630415337,\n",
       " 8.014740312707115,\n",
       " 6.197397705235315,\n",
       " 8.032750017355246,\n",
       " 7.942997933122791,\n",
       " 7.347241920596126,\n",
       " 7.973474764143468,\n",
       " 7.958248765451344,\n",
       " 7.176601586372508,\n",
       " 7.161016492295136,\n",
       " 7.575609770972679,\n",
       " 6.784891873463194,\n",
       " 7.314379365298005,\n",
       " 6.787194165345387,\n",
       " 8.52704754602821,\n",
       " 7.261921637340486,\n",
       " 6.492519207168813,\n",
       " 7.248260680880417,\n",
       " 6.582358826132824,\n",
       " 7.125950151027002,\n",
       " 6.737347333309946,\n",
       " 6.86306907073596,\n",
       " 6.721815364374989,\n",
       " 6.614448674087128,\n",
       " 6.103465669052623,\n",
       " 6.982968439184154,\n",
       " 8.140103668848825,\n",
       " 7.180914272731558,\n",
       " 6.895557608898335,\n",
       " 7.160615683833432,\n",
       " 6.444927226050298,\n",
       " 7.4594163685335655,\n",
       " 7.676267560403153,\n",
       " 6.819139263784942,\n",
       " 6.7151122687464415,\n",
       " 7.724370680949805,\n",
       " 6.43848804631671,\n",
       " 7.220343549066534,\n",
       " 6.787408755140137,\n",
       " 5.576335745399291,\n",
       " 7.333917333429109,\n",
       " 6.525708593416888,\n",
       " 6.294599154589938,\n",
       " 6.401326244789109,\n",
       " 6.509794815061635,\n",
       " 6.829296379219431,\n",
       " 6.544642343394845,\n",
       " 7.287698182677182,\n",
       " 7.54062760685586,\n",
       " 8.353843117134039,\n",
       " 5.598884492182394,\n",
       " 7.354152664838531,\n",
       " 7.148816237458292,\n",
       " 6.549497993212217,\n",
       " 8.177159156741842,\n",
       " 5.934738479105038,\n",
       " 6.531333805956591,\n",
       " 7.2313618174305585,\n",
       " 7.030253391632078,\n",
       " 6.972125986415605,\n",
       " 7.290614337924054,\n",
       " 6.776067964156755,\n",
       " 6.904787847962182,\n",
       " 8.104541545416186,\n",
       " 6.924553786456749,\n",
       " 7.0124372108073905,\n",
       " 6.930591592367502,\n",
       " 7.171990160427298,\n",
       " 7.2705596370456576,\n",
       " 6.199540536485683,\n",
       " 6.874284988153334,\n",
       " 6.948028692383769,\n",
       " 6.570287611903499,\n",
       " 6.447460338060222,\n",
       " 5.745504835720319,\n",
       " 6.479975437615729,\n",
       " 6.944198694352933,\n",
       " 7.156339567672936,\n",
       " 7.690255149225385,\n",
       " 6.933415224656988,\n",
       " 6.286343922584402,\n",
       " 6.971944672703779,\n",
       " 7.070499212495766,\n",
       " 6.727034461395052,\n",
       " 6.3765385645874355,\n",
       " 7.0799551094151125,\n",
       " 6.74092190629201,\n",
       " 6.126751683852291,\n",
       " 6.431299347381743,\n",
       " 6.133641459817258,\n",
       " 7.230597373699986,\n",
       " 6.266818584019848,\n",
       " 6.778556394328369,\n",
       " 6.734013056956408,\n",
       " 7.473800380457968,\n",
       " 6.963148281805858,\n",
       " 6.389058797330676,\n",
       " 6.416142397655233,\n",
       " 6.675466990755836,\n",
       " 7.948377123592601,\n",
       " 5.933403112120319,\n",
       " 6.662816438137217,\n",
       " 6.593099649066718,\n",
       " 6.3607800565897445,\n",
       " 6.917502748408753,\n",
       " 6.4504596604634035,\n",
       " 6.345485528194669,\n",
       " 6.447093322857881,\n",
       " 7.198137361384479,\n",
       " 6.742644594948004,\n",
       " 6.954077448195082,\n",
       " 5.615614979356246,\n",
       " 6.5370728705452255,\n",
       " 6.6362493809311625,\n",
       " 6.505690854226735,\n",
       " 6.892356749014604,\n",
       " 6.438744026124988,\n",
       " 7.025140658116115,\n",
       " 7.281647484991309,\n",
       " 6.719549990460172,\n",
       " 6.024098566457964,\n",
       " 6.211408282956553,\n",
       " 5.957405585300467,\n",
       " 6.568371331658663,\n",
       " 7.026981422508829,\n",
       " 7.22482412638063,\n",
       " 6.259311583122291,\n",
       " 6.450535904418105,\n",
       " 6.685441816648977,\n",
       " 6.556404658645723,\n",
       " 6.245549168385869,\n",
       " 8.482888703754098,\n",
       " 6.535978852858842,\n",
       " 7.314412017516144,\n",
       " 6.955305346088796,\n",
       " 6.838982812805665,\n",
       " 6.658524231960734,\n",
       " 6.446506749323035,\n",
       " 7.132774405582331,\n",
       " 6.987813795262561,\n",
       " 6.189530735526074,\n",
       " 6.757398191378857,\n",
       " 6.4059322158921574,\n",
       " 6.728700521909113,\n",
       " 7.08143531512201,\n",
       " 6.3324636270798536,\n",
       " 6.947890308616584,\n",
       " 6.16748202188899,\n",
       " 7.115439175451805,\n",
       " 6.735368466721262,\n",
       " 5.7534335965795105,\n",
       " 6.651589978050806,\n",
       " 7.36081165754286,\n",
       " 7.145799963359336,\n",
       " 6.345883442480911,\n",
       " 6.359907174877239,\n",
       " 7.505446550456674,\n",
       " 6.544022036466377,\n",
       " 6.509533911595454,\n",
       " 5.946617259040729,\n",
       " 6.2593771211565326,\n",
       " 6.5451423098685435,\n",
       " 6.720656479084112,\n",
       " 7.305163975301568,\n",
       " 6.895291825172272,\n",
       " 6.957927200129726,\n",
       " 5.965740084733605,\n",
       " 7.165848424528336,\n",
       " 6.66200623458364,\n",
       " 6.722060112102168,\n",
       " 6.094290620502969,\n",
       " 6.538109650566402,\n",
       " 5.835058659677233,\n",
       " 6.0461707636615385,\n",
       " 7.706268517865135,\n",
       " 7.03739652516224,\n",
       " 6.7103471430265795,\n",
       " 7.3464241703417485,\n",
       " 6.343891806683768,\n",
       " 7.164061382438394,\n",
       " 6.500728506138669,\n",
       " 7.078972164674542,\n",
       " 6.144971607143532,\n",
       " 7.140446478630263,\n",
       " 7.09108130150899,\n",
       " 6.489327927932237,\n",
       " 7.060848500910102,\n",
       " 6.766587887648282,\n",
       " 6.625119082490957,\n",
       " 6.186950527563878,\n",
       " 6.79142323197487,\n",
       " 5.3740009502874635,\n",
       " 6.193765745461482,\n",
       " 6.90988662172378,\n",
       " 6.604762692215909,\n",
       " 6.156185771741269,\n",
       " 6.54438455058634,\n",
       " 6.730844813925399,\n",
       " 7.201224226222414,\n",
       " 6.7006312892156625,\n",
       " 7.366848161727721,\n",
       " 7.192913343687089,\n",
       " 5.556922309708763,\n",
       " 6.267185722210434,\n",
       " 5.318466903001123,\n",
       " 6.616670346607418,\n",
       " 6.960535955637372,\n",
       " 6.722200112664885,\n",
       " 6.349231300895408,\n",
       " 6.5425591710947435,\n",
       " 6.713219551546647,\n",
       " 5.800299865751044,\n",
       " 6.530588028066751,\n",
       " 6.509408077993222,\n",
       " 6.202885093515589,\n",
       " 7.358065419864815,\n",
       " 7.396728787942395,\n",
       " 6.889292701912797,\n",
       " 7.37764165717595,\n",
       " 7.083986574096956,\n",
       " 7.29155350925402,\n",
       " 7.411364849406496,\n",
       " 6.7872035409118885,\n",
       " 6.375562880379895,\n",
       " 6.035119191699081,\n",
       " 7.70814401067362,\n",
       " 7.438892729176857,\n",
       " 6.5625566989968815,\n",
       " 7.356362591953438,\n",
       " 7.176140490190341,\n",
       " 6.567543973265789,\n",
       " 7.585695888408766,\n",
       " 7.335529170605509,\n",
       " 7.384636441008955,\n",
       " 6.8458245158290785,\n",
       " 7.131968926046101,\n",
       " 7.276015418500356,\n",
       " 6.719608169986936,\n",
       " 7.613848772252693,\n",
       " 6.8877253592333485,\n",
       " 6.935113842778996,\n",
       " 7.726190851942182,\n",
       " 7.661505478163585,\n",
       " 6.549389162266487,\n",
       " 7.190021588999668,\n",
       " 6.227969046911429,\n",
       " 6.1714127190320465,\n",
       " 8.094828583222151,\n",
       " 6.983761444737874,\n",
       " 7.2368892463147105,\n",
       " 8.334655008881375,\n",
       " 6.082412152186684,\n",
       " 7.0330001432534335,\n",
       " 6.633499790842104,\n",
       " 7.008662654435382,\n",
       " 6.938784701436546,\n",
       " 6.816399530501947,\n",
       " 6.907306157449888,\n",
       " 6.3946873843141825,\n",
       " 7.237209893183669,\n",
       " 6.8396670509237145,\n",
       " 7.347586721745364,\n",
       " 7.624958552290075,\n",
       " 7.920115330511285,\n",
       " 7.207666005254225,\n",
       " 6.692894526861924,\n",
       " 6.932965775818421,\n",
       " 7.204808341245027,\n",
       " 7.323298081452715,\n",
       " 6.492911095432728,\n",
       " 7.83126876006404,\n",
       " 6.714788288396161,\n",
       " 7.303438845920201,\n",
       " 6.586668603352727,\n",
       " 7.754835894701838,\n",
       " 6.885765061549441,\n",
       " 7.316843502350369,\n",
       " 6.857385770912506,\n",
       " 6.466988480071903,\n",
       " 7.311534698061361,\n",
       " 6.559708546141186,\n",
       " 8.967802398583958,\n",
       " 7.2520220827980735,\n",
       " 6.8961802810334545,\n",
       " 6.8059090436261975,\n",
       " 7.37763938786397,\n",
       " 7.707076967897934,\n",
       " 6.596288775868079,\n",
       " 6.449754408280167,\n",
       " 7.0803636661525,\n",
       " 7.778673950074203,\n",
       " 7.568945396365287,\n",
       " 7.339529104867419,\n",
       " 7.073836504160842,\n",
       " 7.313463061261751,\n",
       " 6.544449162674778,\n",
       " 7.875927629535701,\n",
       " 7.087580797370507,\n",
       " 7.230051171590726,\n",
       " 6.460796550884651,\n",
       " 7.007185241918387,\n",
       " 7.678465442990424,\n",
       " 7.499357789942286,\n",
       " 8.10579959690149,\n",
       " 7.382304836487661,\n",
       " 7.2394818780404675,\n",
       " 6.215151899510311,\n",
       " 6.571070899757266,\n",
       " 7.266893964787737,\n",
       " 7.844423794092358,\n",
       " 7.29403085336741,\n",
       " 6.547368309404066,\n",
       " 7.19198314865763,\n",
       " 6.5523489945403375,\n",
       " 7.122084961547077,\n",
       " 6.417200555089844,\n",
       " 6.452989888327906,\n",
       " 8.082739010325499,\n",
       " 7.384704732918135,\n",
       " 7.202232393165779,\n",
       " 6.442019548571491,\n",
       " 7.448567431335319,\n",
       " 6.946814157783303,\n",
       " 6.666277394514783,\n",
       " 6.178187464578434,\n",
       " 6.920052774415264,\n",
       " 6.874377092074424,\n",
       " 7.415955067947991,\n",
       " 7.249634643526787,\n",
       " 7.64270929327938,\n",
       " 7.3789322467977385,\n",
       " 6.72706350937072,\n",
       " 6.532626921724463,\n",
       " 5.896417183759635,\n",
       " 8.521783211843676,\n",
       " 7.301172993330389,\n",
       " 7.278310937964207,\n",
       " 5.245525260488934,\n",
       " 7.07434423236973,\n",
       " 7.702902906980504,\n",
       " 6.346348008746999,\n",
       " 7.316302944388691,\n",
       " 6.624796913357558,\n",
       " 7.219685995525328,\n",
       " 7.189872616260132,\n",
       " 6.640257228377786,\n",
       " 6.906507734241792,\n",
       " 7.313351039861044,\n",
       " 7.266574551021178,\n",
       " 7.047746203888999,\n",
       " 7.195065940320927,\n",
       " 5.950734577575522,\n",
       " 6.037006414239026,\n",
       " 5.772632652614752,\n",
       " 5.878143352337715,\n",
       " 4.982123015430011,\n",
       " 4.838553129687009,\n",
       " 5.935477323064346,\n",
       " 6.26510969227677,\n",
       " 5.999213025931283,\n",
       " 5.187609642208242,\n",
       " 5.893344294872183,\n",
       " 5.934650904503278,\n",
       " 5.805990525081396,\n",
       " 5.6012177552279425,\n",
       " 6.2142707158249735,\n",
       " 4.720163375875126,\n",
       " 5.470549472683627,\n",
       " 5.976365008250377,\n",
       " 6.181166106622618,\n",
       " 5.809850986341291,\n",
       " 5.27849032554277,\n",
       " 5.465480744197133,\n",
       " 6.179079861036033,\n",
       " 6.2937144038568915,\n",
       " 5.70826965844776,\n",
       " 5.89030395312381,\n",
       " 6.492160038868733,\n",
       " 4.712861854401967,\n",
       " 5.930390910233649,\n",
       " 5.533496395628606,\n",
       " 5.521131408256599,\n",
       " 5.973657634973986,\n",
       " 6.132291522885621,\n",
       " 6.887990779061452,\n",
       " 5.555613235776885,\n",
       " 6.006242119464199,\n",
       " 5.360679826183042,\n",
       " 5.9331209739137005,\n",
       " 5.688121675899907,\n",
       " 5.636133161467045,\n",
       " 5.483196079704446,\n",
       " 5.926467892784217,\n",
       " 5.878089621040432,\n",
       " 5.353253333021195,\n",
       " 6.2695112456106505,\n",
       " 5.773762683603321,\n",
       " 5.551325032125022,\n",
       " 6.114674180937816,\n",
       " 5.74114956142395,\n",
       " 5.559701777640234,\n",
       " 6.010144853121031,\n",
       " 5.512478009907232,\n",
       " 5.868020944957205,\n",
       " 5.141030945052138,\n",
       " 5.936512225123953,\n",
       " 6.26115058193581,\n",
       " 5.43527297190059,\n",
       " 5.767589612428092,\n",
       " 5.675614556353009,\n",
       " 4.883119288226796,\n",
       " 5.245196611143082,\n",
       " 5.335623820855378,\n",
       " 6.28332298062843,\n",
       " 5.639203839046536,\n",
       " 5.910131204115819,\n",
       " 6.156322830955526,\n",
       " 5.487477778803466,\n",
       " 5.170159115128673,\n",
       " 5.987980848050113,\n",
       " 5.760972982945382,\n",
       " 5.7576132976072465,\n",
       " 5.800928982356195,\n",
       " 5.873141459095035,\n",
       " 5.164732140388202,\n",
       " 7.185830356033483,\n",
       " 5.681497286760911,\n",
       " 5.470707021909176,\n",
       " 5.512013433147895,\n",
       " 6.118768023299495,\n",
       " 6.319276986465216,\n",
       " 5.213110730647393,\n",
       " 5.350066575829086,\n",
       " 6.154014896912831,\n",
       " 6.0078020112667065,\n",
       " 5.289740002102707,\n",
       " 4.5880387102877345,\n",
       " 5.83331330969755,\n",
       " 6.349761519133141,\n",
       " 5.7632033189588,\n",
       " 5.6630591391880705,\n",
       " 6.439551878755301,\n",
       " 5.878778568961284,\n",
       " 5.955516375403371,\n",
       " 6.103220288009271,\n",
       " 6.421213741112157,\n",
       " 6.04327453984677,\n",
       " 5.316550239971342,\n",
       " 6.300086810574292,\n",
       " 5.6157718325154296,\n",
       " 5.885744548886403,\n",
       " 5.164273726355927,\n",
       " 6.770152294828871,\n",
       " 5.71097320045646,\n",
       " 5.196002062334571,\n",
       " 4.931455154153112,\n",
       " 5.1927957575987405,\n",
       " 6.575286560171334,\n",
       " 5.94464298689912,\n",
       " 6.287921871594803,\n",
       " 5.367002826135463,\n",
       " 5.590665841277829,\n",
       " 6.073633869291806,\n",
       " 5.996975245567207,\n",
       " 5.227172979906197,\n",
       " 6.0062384794483865,\n",
       " 5.791674132758303,\n",
       " 5.413533618406065,\n",
       " 6.17175697066275,\n",
       " 6.0836848172537685,\n",
       " 6.043531851218507,\n",
       " 5.256609577482892,\n",
       " 5.235025407896527,\n",
       " 5.9105397088303855,\n",
       " 5.346551574837117,\n",
       " 5.379581722788491,\n",
       " 5.910604576301511,\n",
       " 6.030402476472103,\n",
       " 5.8907435513696225,\n",
       " 5.937821570575537,\n",
       " 5.991736380739813,\n",
       " 4.196897094914301,\n",
       " 6.506076408599808,\n",
       " 6.047613210548311,\n",
       " 4.59949839320012,\n",
       " 6.543938948715393,\n",
       " 5.854628862905456,\n",
       " 5.46671194691974,\n",
       " 5.272824980807524,\n",
       " 5.907252507679723,\n",
       " 5.9484676454445005,\n",
       " 5.607974622942723,\n",
       " 5.7268629015225025,\n",
       " 5.769771755383262,\n",
       " 5.788197330980083,\n",
       " 7.190961158479207,\n",
       " 7.173270078155774,\n",
       " 7.208372025667739,\n",
       " 7.208912702616299,\n",
       " 6.426091544592137,\n",
       " 5.993211920090718,\n",
       " 6.703727961071827,\n",
       " 7.177653406211698,\n",
       " 6.424914368636075,\n",
       " 6.804049832127457,\n",
       " 7.161129467277975,\n",
       " 7.184829777894194,\n",
       " 6.420544915519005,\n",
       " 7.227669053961586,\n",
       " 6.561736280608622,\n",
       " 7.5728544066136605,\n",
       " 6.399323366148209,\n",
       " 6.828882631534477,\n",
       " 7.5944767801523385,\n",
       " 6.41758222587538,\n",
       " 7.150200016712413,\n",
       " 7.233989174092648,\n",
       " 7.17412950274401,\n",
       " 6.7732057158014065,\n",
       " 7.191218187584234,\n",
       " 6.792490367584954,\n",
       " 7.194842170377941,\n",
       " 8.288666367570206,\n",
       " 6.014150249186437,\n",
       " 6.7797390817818135,\n",
       " 7.564347064686469,\n",
       " 6.416259128079839,\n",
       " 6.774764934023566,\n",
       " 6.832152347817039,\n",
       " 7.136582886358,\n",
       " 6.800456005507393,\n",
       " 7.186310089686633,\n",
       " 7.5748053835461615,\n",
       " 6.456440966200534,\n",
       " 6.785734679075875,\n",
       " 7.144081131408472,\n",
       " 6.793152875998713,\n",
       " 6.809770509217676,\n",
       " 6.630231972816973,\n",
       " 6.778018905187708,\n",
       " 7.158222404673914,\n",
       " 7.888356841338885,\n",
       " 7.599366308745597,\n",
       " 7.183577893456179,\n",
       " 6.776093509142038,\n",
       " 6.011639412195027,\n",
       " 7.919190887769398,\n",
       " 6.384496614899702,\n",
       " 6.803118295685603,\n",
       " 7.180609570181003,\n",
       " 7.5471582472203576,\n",
       " 6.383946714376714,\n",
       " 6.813435506148992,\n",
       " 7.187700361190622,\n",
       " 7.643927804956754,\n",
       " 6.5802615622803105,\n",
       " 7.599557441090783,\n",
       " 7.1939078606531535,\n",
       " 6.7750208828007175,\n",
       " 6.714184602929894,\n",
       " 6.571944030218858,\n",
       " 7.179142356765856,\n",
       " 7.533574949694862,\n",
       " 7.172304097180097,\n",
       " 7.186622282129484,\n",
       " 7.181793214462557,\n",
       " 6.395656568433505,\n",
       " 7.534847737505391,\n",
       " 7.179828595420772,\n",
       " 6.041125106741977,\n",
       " 7.576189977463708,\n",
       " 7.502768805206728,\n",
       " 6.378484792275566,\n",
       " 6.808758708941951,\n",
       " 7.986759624596832,\n",
       " 7.207583208847281,\n",
       " 7.188318144534213,\n",
       " 7.172161348756211,\n",
       " 7.549195144969744,\n",
       " 6.420863462223504,\n",
       " 7.921516252604107,\n",
       " 7.522973897903974,\n",
       " 7.201281057642298,\n",
       " 7.874398213559371,\n",
       " 6.768730839098699,\n",
       " 6.759327173688142,\n",
       " 7.170950906958348,\n",
       " 6.38758733073089,\n",
       " 7.20327557029594,\n",
       " 6.402989896536814,\n",
       " 7.16475089651361,\n",
       " 7.576585085629476,\n",
       " 6.409888079882824,\n",
       " 7.2211725959450614,\n",
       " 6.476282613896929,\n",
       " 7.944702417517515,\n",
       " 7.167606489357862,\n",
       " 7.161569888442774,\n",
       " 7.572573249023246,\n",
       " 6.029250927778378,\n",
       " 6.710537986984691,\n",
       " 6.446807730502263,\n",
       " 6.483403219048341,\n",
       " 7.633429045124886,\n",
       " 6.4268449547456505,\n",
       " 7.163635290456112,\n",
       " 7.252270050364433,\n",
       " 6.376846512277653,\n",
       " 7.139808170028683,\n",
       " 6.3797012752289275,\n",
       " 6.025716555088889,\n",
       " 6.418413060944435,\n",
       " 7.1900150624563866,\n",
       " 6.417273358677807,\n",
       " 6.811982850815858,\n",
       " 6.414537033389798,\n",
       " 7.170058930664128,\n",
       " 7.2124878406469115,\n",
       " 5.231510882357446,\n",
       " 7.965975034598089,\n",
       " 7.184133405811664,\n",
       " 7.948678594625083,\n",
       " 6.422942533070789,\n",
       " 7.508181160146118,\n",
       " 5.672821019935206,\n",
       " 7.931231360843995,\n",
       " 6.381503638467152,\n",
       " 7.151049027887064,\n",
       " 7.149404831126578,\n",
       " 6.78389716754067,\n",
       " 6.429009317097915,\n",
       " 6.819060615109059,\n",
       " 7.5458833828419305,\n",
       " 6.526059054922611,\n",
       " 6.619210659305231,\n",
       " 6.2553027607618885,\n",
       " 6.606658034214275,\n",
       " 5.689852175814702,\n",
       " 6.614101370394118,\n",
       " 6.565709032085932,\n",
       " 6.430963957788865,\n",
       " 6.239823322032079,\n",
       " 5.236747207071287,\n",
       " 5.741727821610455,\n",
       " 6.164020152723552,\n",
       " 6.728060200735727,\n",
       " 6.1382552745314785,\n",
       " 5.991863397987802,\n",
       " 6.702951662185003,\n",
       " 6.934434549298595,\n",
       " 6.97216650197483,\n",
       " 6.572552229079074,\n",
       " 7.217222795200519,\n",
       " 6.482192540260234,\n",
       " 5.548107139622324,\n",
       " 5.370073171233149,\n",
       " 6.604222832413785,\n",
       " 6.243425281595422,\n",
       " 6.181229441303435,\n",
       " 6.226169451244991,\n",
       " 6.7753285822237,\n",
       " 6.265153420906376,\n",
       " 5.906759564692138,\n",
       " 6.26202105169984,\n",
       " 6.41499234697505,\n",
       " 6.151331971843723,\n",
       " 6.178115856785106,\n",
       " 5.714616883715593,\n",
       " 6.257399946897454,\n",
       " 6.512485757385177,\n",
       " 6.423109577173079,\n",
       " 6.168034917401535,\n",
       " 7.143741642167746,\n",
       " 6.569036015249135,\n",
       " 6.153752132623534,\n",
       " 6.255577008922029,\n",
       " 7.174418486128486,\n",
       " 6.9221965995089185,\n",
       " 6.2635101575728385,\n",
       " 6.853675746263285,\n",
       " 6.903866694352761,\n",
       " 6.159587666644747,\n",
       " 5.812155843983095,\n",
       " 6.522403812921352,\n",
       " 6.587128358159887,\n",
       " 6.757554838433305,\n",
       " 6.692124880354681,\n",
       " 6.421650761301587,\n",
       " 6.871066637899073,\n",
       " 6.587583797835081,\n",
       " 6.564117720722671,\n",
       " 6.265708362442594,\n",
       " 6.114616955116077,\n",
       " 6.115006991054388,\n",
       " 6.787774420878961,\n",
       " 7.151476715579231,\n",
       " 6.535097922255395,\n",
       " 6.01388742786792,\n",
       " 6.756838896663044,\n",
       " 5.85461903388933,\n",
       " 7.07785198625097,\n",
       " 5.845386718259221,\n",
       " 5.487370587038812,\n",
       " 6.379124705240002,\n",
       " 6.9781508903818334,\n",
       " 6.927602672181334,\n",
       " 6.474975022891246,\n",
       " 6.387691477065002,\n",
       " 6.552792442138809,\n",
       " 6.480163520378328,\n",
       " 5.57980047075779,\n",
       " 5.867475995675123,\n",
       " 7.000550851191894,\n",
       " 7.024611769926535,\n",
       " 6.484049195008409,\n",
       " 7.243051925624745,\n",
       " 6.772403580370867,\n",
       " 6.896744599923298,\n",
       " 6.9894782720792765,\n",
       " 6.565738194460474,\n",
       " 5.7421956053274466,\n",
       " 7.548373275553475,\n",
       " 6.475541447458062,\n",
       " 5.496092750007524,\n",
       " 6.582225232607552,\n",
       " 5.8109400891492315,\n",
       " 6.600626764944141,\n",
       " 5.840767053269481,\n",
       " 6.5153587779805555,\n",
       " 6.180263841497618,\n",
       " 5.911243558103992,\n",
       " 6.130070230429392,\n",
       " 6.2150676725545795,\n",
       " 7.246647589577227,\n",
       " 6.198243322158296,\n",
       " 5.851782852704676,\n",
       " 6.47407051230903,\n",
       " 6.1293431851371265,\n",
       " 6.912336702431868,\n",
       " 6.865339074888465,\n",
       " 5.891894589073583,\n",
       " 7.184612954680347,\n",
       " 6.579173224936935,\n",
       " 5.943943824496478,\n",
       " 6.587825636441742,\n",
       " 5.75086591139123,\n",
       " 5.395344718907853,\n",
       " 5.896438789099204,\n",
       " 6.704852689744174,\n",
       " 6.4185434202034255,\n",
       " 5.902373435444409,\n",
       " 6.189460233679773,\n",
       " 6.600810611741857,\n",
       " 6.449245003876273,\n",
       " 4.73025882364828,\n",
       " 7.254312096664099,\n",
       " 5.140077034124943,\n",
       " 7.340484837093917,\n",
       " 6.590377147097128,\n",
       " 6.056564884496632,\n",
       " 6.212473565690897,\n",
       " 6.650842149352832,\n",
       " 5.285335955437247,\n",
       " 5.446848936458036,\n",
       " 4.989688811741064,\n",
       " 4.742825613490692,\n",
       " 4.831380788224673,\n",
       " 5.126247875110701,\n",
       " 5.220777891975396,\n",
       " 4.966961615257519,\n",
       " 4.878608137570776,\n",
       " 4.242945798865558,\n",
       " 4.320643716423686,\n",
       " 4.8949451183653725,\n",
       " 5.285340944129497,\n",
       " 4.580935358563621,\n",
       " 5.2533255389147255,\n",
       " 4.759751868350987,\n",
       " 5.197326546512282,\n",
       " 5.0104038621198885,\n",
       " 5.450607829383258,\n",
       " 5.253720460600049,\n",
       " 5.3276606908205615,\n",
       " 5.284150291184052,\n",
       " 4.833686644054422,\n",
       " 5.40177366746311,\n",
       " 5.431681727590342,\n",
       " 5.105358927987544,\n",
       " 4.65646436176771,\n",
       " 5.4914292901150805,\n",
       " 5.187030758583686,\n",
       " 5.1146508038564376,\n",
       " 4.486619014620921,\n",
       " 4.154158893427211,\n",
       " 5.652435932437544,\n",
       " 4.857467666499513,\n",
       " 4.905653260418209,\n",
       " 5.331606941287846,\n",
       " 5.022334014112226,\n",
       " 5.050411952790704,\n",
       " 5.153913992168898,\n",
       " 5.274141243485802,\n",
       " 4.742126783185203,\n",
       " 5.291447301469433,\n",
       " 5.121087724263537,\n",
       " 4.873249567924717,\n",
       " 4.779633074344217,\n",
       " 4.838869828219109,\n",
       " 5.24778705349273,\n",
       " 4.871143951825457,\n",
       " 4.1854777490193715,\n",
       " 5.291266833618233,\n",
       " 4.9728961714881965,\n",
       " 5.278577409644191,\n",
       " 4.863894242400231,\n",
       " 5.620545297685514,\n",
       " 5.180300881384875,\n",
       " 5.345178513941917,\n",
       " 4.52902230837916,\n",
       " 5.339336337123498,\n",
       " 5.576625822384128,\n",
       " 4.757837132093622,\n",
       " 5.04031282061283,\n",
       " 4.293798204285364,\n",
       " 4.716469800413952,\n",
       " 4.648352632442986,\n",
       " 4.693737080369183,\n",
       " 5.286932337375592,\n",
       " 5.45078580559483,\n",
       " 4.730259871112704,\n",
       " 4.828175255497151,\n",
       " 5.043463025288651,\n",
       " 4.932232960210339,\n",
       " 5.482988150744723,\n",
       " 4.921445522458143,\n",
       " 4.651408269268926,\n",
       " 4.750859491038713,\n",
       " 4.652259950607872,\n",
       " 5.14126967428541,\n",
       " 4.832437215613853,\n",
       " 5.1815582896209404,\n",
       " 5.539967429057609,\n",
       " 5.301026416723614,\n",
       " 5.013696029949853,\n",
       " 5.381782643353136,\n",
       " 5.134665198370276,\n",
       " 4.3499715201164495,\n",
       " 5.110358532818757,\n",
       " 5.624265709998859,\n",
       " 5.507105500349105,\n",
       " 5.096322740791761,\n",
       " 4.75482382730151,\n",
       " 5.048433223841845,\n",
       " 5.210318739121297,\n",
       " 5.006616856631944,\n",
       " 4.446498358604952,\n",
       " 4.731633457850903,\n",
       " 5.044751718861927,\n",
       " 5.036891559417611,\n",
       " 5.328060805197638,\n",
       " 5.560702249730695,\n",
       " 5.20567029226741,\n",
       " 5.130966121845626,\n",
       " 4.52011303352423,\n",
       " 5.399171442895891,\n",
       " 5.006850786239383,\n",
       " 5.171555202830892,\n",
       " 5.985825760581025,\n",
       " 4.8828980315523545,\n",
       " 4.473375952883298,\n",
       " 4.561468996858637,\n",
       " 5.911409225324436,\n",
       " 5.201771433786308,\n",
       " 5.064307400005182,\n",
       " 4.934603996248519,\n",
       " 5.001862652056323,\n",
       " 5.341686839649164,\n",
       " 4.6245199048629635,\n",
       " 5.435759094835375,\n",
       " 5.132880609520631,\n",
       " 5.395296349176758,\n",
       " 5.368888640127376,\n",
       " 4.56161241908967,\n",
       " 4.524885424866879,\n",
       " 5.165642350601934,\n",
       " 5.543846117061921,\n",
       " 5.023685408724063,\n",
       " 4.842866066290278,\n",
       " 4.118660566907798,\n",
       " 5.170168106839648,\n",
       " 4.64922269136408,\n",
       " 5.03617510955553,\n",
       " 6.089364088575643,\n",
       " 5.133125380509976,\n",
       " 3.6541449121216485,\n",
       " 4.112771479159786,\n",
       " 5.191479823939535,\n",
       " 4.70989403361093,\n",
       " 5.06386632111191,\n",
       " 4.503622885076653,\n",
       " 4.458887336920217,\n",
       " 5.1062928776929,\n",
       " 5.13912079579743,\n",
       " 4.990037509093983,\n",
       " 4.867080231910196,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"hw1_predictions_part3.csv\", list_of_predicted_ratings)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
